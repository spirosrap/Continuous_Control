{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Continuous Control\n",
    "\n",
    "---\n",
    "\n",
    "Congratulations for completing the second project of the [Deep Reinforcement Learning Nanodegree](https://www.udacity.com/course/deep-reinforcement-learning-nanodegree--nd893) program!  In this notebook, you will learn how to control an agent in a more challenging environment, where the goal is to train a creature with four arms to walk forward.  **Note that this exercise is optional!**\n",
    "\n",
    "### 1. Start the Environment\n",
    "\n",
    "We begin by importing the necessary packages.  If the code cell below returns an error, please revisit the project instructions to double-check that you have installed [Unity ML-Agents](https://github.com/Unity-Technologies/ml-agents/blob/master/docs/Installation.md) and [NumPy](http://www.numpy.org/)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Environments contain **_brains_** which are responsible for deciding the actions of their associated agents. Here we check for the first brain available, and set it as the default brain we will be controlling from Python."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:unityagents:\n",
      "'Academy' started successfully!\n",
      "Unity Academy name: Academy\n",
      "        Number of Brains: 1\n",
      "        Number of External Brains : 1\n",
      "        Lesson number : 0\n",
      "        Reset Parameters :\n",
      "\t\t\n",
      "Unity brain name: CrawlerBrain\n",
      "        Number of Visual Observations (per agent): 0\n",
      "        Vector Observation space type: continuous\n",
      "        Vector Observation space size (per agent): 129\n",
      "        Number of stacked Vector Observation: 1\n",
      "        Vector Action space type: continuous\n",
      "        Vector Action space size (per agent): 20\n",
      "        Vector Action descriptions: , , , , , , , , , , , , , , , , , , , \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of agents: 12\n",
      "Size of each action: 20\n",
      "There are 12 agents. Each observes a state with length: 129\n",
      "The state for the first agent looks like: [ 0.00000000e+00  0.00000000e+00  0.00000000e+00  2.25000000e+00\n",
      "  1.00000000e+00  0.00000000e+00  1.78813934e-07  0.00000000e+00\n",
      "  1.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "  0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "  0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "  0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "  6.06093168e-01 -1.42857209e-01 -6.06078804e-01  0.00000000e+00\n",
      "  0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "  0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "  0.00000000e+00  0.00000000e+00  1.33339906e+00 -1.42857209e-01\n",
      " -1.33341408e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "  0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "  0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      " -6.06093347e-01 -1.42857209e-01 -6.06078625e-01  0.00000000e+00\n",
      "  0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "  0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "  0.00000000e+00  0.00000000e+00 -1.33339953e+00 -1.42857209e-01\n",
      " -1.33341372e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "  0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "  0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      " -6.06093168e-01 -1.42857209e-01  6.06078804e-01  0.00000000e+00\n",
      "  0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "  0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "  0.00000000e+00  0.00000000e+00 -1.33339906e+00 -1.42857209e-01\n",
      "  1.33341408e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "  0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "  0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "  6.06093347e-01 -1.42857209e-01  6.06078625e-01  0.00000000e+00\n",
      "  0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "  0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "  0.00000000e+00  0.00000000e+00  1.33339953e+00 -1.42857209e-01\n",
      "  1.33341372e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "  0.00000000e+00]\n"
     ]
    }
   ],
   "source": [
    "from unityagents import UnityEnvironment\n",
    "import numpy as np\n",
    "\n",
    "env = UnityEnvironment(file_name='Crawler_Linux_NoVis/Crawler.x86_64')\n",
    "\n",
    "# get the default brain\n",
    "brain_name = env.brain_names[0]\n",
    "brain = env.brains[brain_name]\n",
    "\n",
    "# reset the environment\n",
    "env_info = env.reset(train_mode=True)[brain_name]\n",
    "\n",
    "# number of agents\n",
    "num_agents = len(env_info.agents)\n",
    "print('Number of agents:', num_agents)\n",
    "\n",
    "# size of each action\n",
    "action_size = brain.vector_action_space_size\n",
    "print('Size of each action:', action_size)\n",
    "\n",
    "# examine the state space \n",
    "states = env_info.vector_observations\n",
    "state_size = states.shape[1]\n",
    "print('There are {} agents. Each observes a state with length: {}'.format(states.shape[0], state_size))\n",
    "print('The state for the first agent looks like:', states[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#######################################################################\n",
    "# Copyright (C) 2017 Shangtong Zhang(zhangshangtong.cpp@gmail.com)    #\n",
    "# Permission given to modify the code as long as you keep this        #\n",
    "# declaration at the top                                              #\n",
    "#######################################################################\n",
    "\n",
    "from deep_rl import *\n",
    "\n",
    "import torch\n",
    "import numpy as np\n",
    "from deep_rl.utils import *\n",
    "import torch.multiprocessing as mp\n",
    "from collections import deque\n",
    "from skimage.io import imsave\n",
    "from deep_rl.network import *\n",
    "from deep_rl.component import *\n",
    "\n",
    "\n",
    "class BaseAgent:\n",
    "    def __init__(self, config):\n",
    "        self.config = config\n",
    "        self.logger = get_logger(tag=config.tag, log_level=config.log_level)\n",
    "        self.task_ind = 0\n",
    "        self.episode_rewards = []\n",
    "        self.rewards = None\n",
    "        self.episodic_return = None\n",
    "    def close(self):\n",
    "        close_obj(self.task)\n",
    "\n",
    "    def save(self, filename):\n",
    "        torch.save(self.network.state_dict(), '%s.model' % (filename))\n",
    "        with open('%s.stats' % (filename), 'wb') as f:\n",
    "            pickle.dump(self.config.state_normalizer.state_dict(), f)\n",
    "\n",
    "    def load(self, filename):\n",
    "        state_dict = torch.load('%s.model' % filename, map_location=lambda storage, loc: storage)\n",
    "        self.network.load_state_dict(state_dict)\n",
    "        with open('%s.stats' % (filename), 'rb') as f:\n",
    "            self.config.state_normalizer.load_state_dict(pickle.load(f))\n",
    "\n",
    "    def eval_step(self, state):\n",
    "        raise NotImplementedError\n",
    "\n",
    "    def eval_episode(self):\n",
    "        env = self.config.eval_env\n",
    "        state = env.reset()\n",
    "        while True:\n",
    "            action = self.eval_step(state)\n",
    "            state, reward, done, info = env.step(action)\n",
    "            ret = info[0]['episodic_return']\n",
    "            if ret is not None:\n",
    "                break\n",
    "        return ret\n",
    "\n",
    "    def eval_episodes(self):\n",
    "        episodic_returns = []\n",
    "        for ep in range(self.config.eval_episodes):\n",
    "            total_rewards = self.eval_episode()\n",
    "            episodic_returns.append(np.sum(total_rewards))\n",
    "        self.episode_rewards = episodic_returns\n",
    "        self.logger.info('steps %d, episodic_return_test %.2f(%.2f)' % (\n",
    "            self.total_steps, np.mean(episodic_returns), np.std(episodic_returns) / np.sqrt(len(episodic_returns))\n",
    "        ))\n",
    "        self.logger.add_scalar('episodic_return_test', np.mean(episodic_returns), self.total_steps)\n",
    "        return {\n",
    "            'episodic_return_test': np.mean(episodic_returns),\n",
    "        }\n",
    "\n",
    "    def record_online_return(self, info, offset=0):\n",
    "        if isinstance(info, dict):\n",
    "            ret = info['episodic_return']\n",
    "            self.rewards = info['all_rewards']\n",
    "            if(self.rewards is not None):\n",
    "                episode = len(self.rewards)\n",
    "            if ret is not None:\n",
    "                self.episodic_return = ret\n",
    "#                 self.logger.add_scalar('episodic_return_train', ret, self.total_steps + offset)\n",
    "#                 self.logger.info('Episode %d, steps %d, episodic_return_train %s' % (episode,self.total_steps + offset, ret))\n",
    "        elif isinstance(info, tuple):\n",
    "            for i, info_ in enumerate(info):\n",
    "                self.record_online_return(info_, i)\n",
    "        else:\n",
    "            raise NotImplementedError\n",
    "\n",
    "    def switch_task(self):\n",
    "        config = self.config\n",
    "        if not config.tasks:\n",
    "            return\n",
    "        segs = np.linspace(0, config.max_steps, len(config.tasks) + 1)\n",
    "        if self.total_steps > segs[self.task_ind + 1]:\n",
    "            self.task_ind += 1\n",
    "            self.task = config.tasks[self.task_ind]\n",
    "            self.states = self.task.reset()\n",
    "            self.states = config.state_normalizer(self.states)\n",
    "\n",
    "    def record_episode(self, dir, env):\n",
    "        mkdir(dir)\n",
    "        steps = 0\n",
    "        state = env.reset()\n",
    "        while True:\n",
    "            self.record_obs(env, dir, steps)\n",
    "            action = self.record_step(state)\n",
    "            state, reward, done, info = env.step(action)\n",
    "            ret = info[0]['episodic_return']\n",
    "            steps += 1\n",
    "            if ret is not None:\n",
    "                break\n",
    "\n",
    "    def record_step(self, state):\n",
    "        raise NotImplementedError\n",
    "\n",
    "    # For DMControl\n",
    "    def record_obs(self, env, dir, steps):\n",
    "        env = env.env.envs[0]\n",
    "        obs = env.render(mode='rgb_array')\n",
    "        imsave('%s/%04d.png' % (dir, steps), obs)\n",
    "\n",
    "class PPOAgent(BaseAgent):\n",
    "    def __init__(self, config):\n",
    "        BaseAgent.__init__(self, config)\n",
    "        self.config = config\n",
    "        self.task = config.task_fn()\n",
    "        self.network = config.network_fn()\n",
    "        self.opt = config.optimizer_fn(self.network.parameters())\n",
    "        self.total_steps = 0\n",
    "        self.states = self.task.reset()\n",
    "        self.states = config.state_normalizer(self.states)\n",
    "\n",
    "    def step(self):\n",
    "        config = self.config\n",
    "        storage = Storage(config.rollout_length)\n",
    "        states = self.states\n",
    "        for _ in range(config.rollout_length):\n",
    "            prediction = self.network(states)\n",
    "            next_states, rewards, terminals, info = self.task.step(to_np(prediction['a']))\n",
    "            self.record_online_return(info)\n",
    "            rewards = config.reward_normalizer(rewards)\n",
    "            next_states = config.state_normalizer(next_states)\n",
    "            storage.add(prediction)\n",
    "            storage.add({'r': tensor(rewards).unsqueeze(-1),\n",
    "                         'm': tensor(1 - terminals).unsqueeze(-1),\n",
    "                         's': tensor(states)})\n",
    "            states = next_states\n",
    "            self.total_steps += config.num_workers\n",
    "\n",
    "        self.states = states\n",
    "        prediction = self.network(states)\n",
    "        storage.add(prediction)\n",
    "        storage.placeholder()\n",
    "\n",
    "        advantages = tensor(np.zeros((config.num_workers, 1)))\n",
    "        returns = prediction['v'].detach()\n",
    "        for i in reversed(range(config.rollout_length)):\n",
    "            returns = storage.r[i] + config.discount * storage.m[i] * returns\n",
    "            if not config.use_gae:\n",
    "                advantages = returns - storage.v[i].detach()\n",
    "            else:\n",
    "                td_error = storage.r[i] + config.discount * storage.m[i] * storage.v[i + 1] - storage.v[i]\n",
    "                advantages = advantages * config.gae_tau * config.discount * storage.m[i] + td_error\n",
    "            storage.adv[i] = advantages.detach()\n",
    "            storage.ret[i] = returns.detach()\n",
    "\n",
    "        states, actions, log_probs_old, returns, advantages = storage.cat(['s', 'a', 'log_pi_a', 'ret', 'adv'])\n",
    "        actions = actions.detach()\n",
    "        log_probs_old = log_probs_old.detach()\n",
    "        advantages = (advantages - advantages.mean()) / advantages.std()\n",
    "\n",
    "        for _ in range(config.optimization_epochs):\n",
    "            sampler = random_sample(np.arange(states.size(0)), config.mini_batch_size)\n",
    "            for batch_indices in sampler:\n",
    "                batch_indices = tensor(batch_indices).long()\n",
    "                sampled_states = states[batch_indices]\n",
    "                sampled_actions = actions[batch_indices]\n",
    "                sampled_log_probs_old = log_probs_old[batch_indices]\n",
    "                sampled_returns = returns[batch_indices]\n",
    "                sampled_advantages = advantages[batch_indices]\n",
    "\n",
    "                prediction = self.network(sampled_states, sampled_actions)\n",
    "                ratio = (prediction['log_pi_a'] - sampled_log_probs_old).exp()\n",
    "                obj = ratio * sampled_advantages\n",
    "                obj_clipped = ratio.clamp(1.0 - self.config.ppo_ratio_clip,\n",
    "                                          1.0 + self.config.ppo_ratio_clip) * sampled_advantages\n",
    "                policy_loss = -torch.min(obj, obj_clipped).mean() - config.entropy_weight * prediction['ent'].mean()\n",
    "\n",
    "                value_loss = 0.5 * (sampled_returns - prediction['v']).pow(2).mean()\n",
    "\n",
    "                self.opt.zero_grad()\n",
    "                (policy_loss + value_loss).backward()\n",
    "                nn.utils.clip_grad_norm_(self.network.parameters(), config.gradient_clip)\n",
    "                self.opt.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Episode 16,last 16 episodes, mean rewards  0.96,  steps 12288, 802.09 steps/s\n",
      "INFO:root:Episode 32,last 32 episodes, mean rewards  2.15,  steps 24576, 800.68 steps/s\n",
      "INFO:root:Episode 48,last 48 episodes, mean rewards  3.22,  steps 36864, 801.93 steps/s\n",
      "INFO:root:Episode 64,last 64 episodes, mean rewards  3.76,  steps 49152, 786.38 steps/s\n",
      "INFO:root:Episode 80,last 80 episodes, mean rewards  4.57,  steps 61440, 801.91 steps/s\n",
      "INFO:root:Episode 96,last 96 episodes, mean rewards  5.36,  steps 73728, 806.23 steps/s\n",
      "INFO:root:Episode 112,last 100 episodes, mean rewards  6.43,  steps 86016, 800.45 steps/s\n",
      "INFO:root:Episode 128,last 100 episodes, mean rewards  7.08,  steps 98304, 797.35 steps/s\n",
      "INFO:root:Episode 144,last 100 episodes, mean rewards  7.85,  steps 110592, 810.01 steps/s\n",
      "INFO:root:Episode 160,last 100 episodes, mean rewards  8.66,  steps 122880, 811.91 steps/s\n",
      "INFO:root:Episode 176,last 100 episodes, mean rewards  9.19,  steps 135168, 791.20 steps/s\n",
      "INFO:root:Episode 192,last 100 episodes, mean rewards  9.63,  steps 147456, 788.63 steps/s\n",
      "INFO:root:Episode 208,last 100 episodes, mean rewards  10.34,  steps 159744, 799.85 steps/s\n",
      "INFO:root:Episode 224,last 100 episodes, mean rewards  11.17,  steps 172032, 797.00 steps/s\n",
      "INFO:root:Episode 240,last 100 episodes, mean rewards  11.63,  steps 184320, 785.93 steps/s\n",
      "INFO:root:Episode 256,last 100 episodes, mean rewards  11.59,  steps 196608, 791.22 steps/s\n",
      "INFO:root:Episode 272,last 100 episodes, mean rewards  11.94,  steps 208896, 787.38 steps/s\n",
      "INFO:root:Episode 288,last 100 episodes, mean rewards  12.44,  steps 221184, 796.15 steps/s\n",
      "INFO:root:Episode 304,last 100 episodes, mean rewards  12.29,  steps 233472, 791.77 steps/s\n",
      "INFO:root:Episode 320,last 100 episodes, mean rewards  12.46,  steps 245760, 794.67 steps/s\n",
      "INFO:root:Episode 336,last 100 episodes, mean rewards  12.69,  steps 258048, 803.40 steps/s\n",
      "INFO:root:Episode 352,last 100 episodes, mean rewards  13.21,  steps 270336, 795.82 steps/s\n",
      "INFO:root:Episode 368,last 100 episodes, mean rewards  13.77,  steps 282624, 785.05 steps/s\n",
      "INFO:root:Episode 384,last 100 episodes, mean rewards  13.76,  steps 294912, 805.25 steps/s\n",
      "INFO:root:Episode 400,last 100 episodes, mean rewards  13.79,  steps 307200, 791.34 steps/s\n",
      "INFO:root:Episode 416,last 100 episodes, mean rewards  13.78,  steps 319488, 795.01 steps/s\n",
      "INFO:root:Episode 432,last 100 episodes, mean rewards  13.99,  steps 331776, 791.23 steps/s\n",
      "INFO:root:Episode 448,last 100 episodes, mean rewards  14.07,  steps 344064, 797.48 steps/s\n",
      "INFO:root:Episode 464,last 100 episodes, mean rewards  14.14,  steps 356352, 786.65 steps/s\n",
      "INFO:root:Episode 480,last 100 episodes, mean rewards  14.12,  steps 368640, 798.60 steps/s\n",
      "INFO:root:Episode 496,last 100 episodes, mean rewards  14.43,  steps 380928, 800.03 steps/s\n",
      "INFO:root:Episode 512,last 100 episodes, mean rewards  14.31,  steps 393216, 810.76 steps/s\n",
      "INFO:root:Episode 528,last 100 episodes, mean rewards  14.61,  steps 405504, 786.63 steps/s\n",
      "INFO:root:Episode 544,last 100 episodes, mean rewards  14.53,  steps 417792, 784.90 steps/s\n",
      "INFO:root:Episode 560,last 100 episodes, mean rewards  14.76,  steps 430080, 790.12 steps/s\n",
      "INFO:root:Episode 576,last 100 episodes, mean rewards  15.35,  steps 442368, 809.05 steps/s\n",
      "INFO:root:Episode 592,last 100 episodes, mean rewards  15.22,  steps 454656, 799.36 steps/s\n",
      "INFO:root:Episode 608,last 100 episodes, mean rewards  15.18,  steps 466944, 789.11 steps/s\n",
      "INFO:root:Episode 624,last 100 episodes, mean rewards  15.56,  steps 479232, 806.99 steps/s\n",
      "INFO:root:Episode 640,last 100 episodes, mean rewards  16.00,  steps 491520, 793.85 steps/s\n",
      "INFO:root:Episode 656,last 100 episodes, mean rewards  16.11,  steps 503808, 789.02 steps/s\n",
      "INFO:root:Episode 672,last 100 episodes, mean rewards  16.31,  steps 516096, 812.91 steps/s\n",
      "INFO:root:Episode 688,last 100 episodes, mean rewards  16.48,  steps 528384, 794.22 steps/s\n",
      "INFO:root:Episode 704,last 100 episodes, mean rewards  16.97,  steps 540672, 797.51 steps/s\n",
      "INFO:root:Episode 720,last 100 episodes, mean rewards  17.17,  steps 552960, 806.63 steps/s\n",
      "INFO:root:Episode 736,last 100 episodes, mean rewards  17.54,  steps 565248, 805.75 steps/s\n",
      "INFO:root:Episode 752,last 100 episodes, mean rewards  17.61,  steps 577536, 797.90 steps/s\n",
      "INFO:root:Episode 768,last 100 episodes, mean rewards  18.06,  steps 589824, 813.54 steps/s\n",
      "INFO:root:Episode 784,last 100 episodes, mean rewards  18.17,  steps 602112, 802.38 steps/s\n",
      "INFO:root:Episode 800,last 100 episodes, mean rewards  18.64,  steps 614400, 793.41 steps/s\n",
      "INFO:root:Episode 816,last 100 episodes, mean rewards  18.85,  steps 626688, 810.43 steps/s\n",
      "INFO:root:Episode 832,last 100 episodes, mean rewards  19.39,  steps 638976, 801.38 steps/s\n",
      "INFO:root:Episode 848,last 100 episodes, mean rewards  19.13,  steps 651264, 790.63 steps/s\n",
      "INFO:root:Episode 864,last 100 episodes, mean rewards  19.42,  steps 663552, 795.76 steps/s\n",
      "INFO:root:Episode 880,last 100 episodes, mean rewards  19.26,  steps 675840, 796.14 steps/s\n",
      "INFO:root:Episode 896,last 100 episodes, mean rewards  19.56,  steps 688128, 803.01 steps/s\n",
      "INFO:root:Episode 912,last 100 episodes, mean rewards  19.65,  steps 700416, 787.57 steps/s\n",
      "INFO:root:Episode 928,last 100 episodes, mean rewards  19.15,  steps 712704, 793.21 steps/s\n",
      "INFO:root:Episode 944,last 100 episodes, mean rewards  19.10,  steps 724992, 799.19 steps/s\n",
      "INFO:root:Episode 960,last 100 episodes, mean rewards  19.24,  steps 737280, 798.14 steps/s\n",
      "INFO:root:Episode 976,last 100 episodes, mean rewards  19.70,  steps 749568, 800.54 steps/s\n",
      "INFO:root:Episode 992,last 100 episodes, mean rewards  19.75,  steps 761856, 805.63 steps/s\n",
      "INFO:root:Episode 1008,last 100 episodes, mean rewards  19.94,  steps 774144, 799.85 steps/s\n",
      "INFO:root:Episode 1024,last 100 episodes, mean rewards  20.30,  steps 786432, 802.39 steps/s\n",
      "INFO:root:Episode 1040,last 100 episodes, mean rewards  20.49,  steps 798720, 792.31 steps/s\n",
      "INFO:root:Episode 1056,last 100 episodes, mean rewards  20.56,  steps 811008, 797.41 steps/s\n",
      "INFO:root:Episode 1072,last 100 episodes, mean rewards  20.49,  steps 823296, 793.22 steps/s\n",
      "INFO:root:Episode 1088,last 100 episodes, mean rewards  19.80,  steps 835584, 800.87 steps/s\n",
      "INFO:root:Episode 1104,last 100 episodes, mean rewards  19.44,  steps 847872, 794.64 steps/s\n",
      "INFO:root:Episode 1120,last 100 episodes, mean rewards  19.25,  steps 860160, 799.86 steps/s\n",
      "INFO:root:Episode 1136,last 100 episodes, mean rewards  19.49,  steps 872448, 792.23 steps/s\n",
      "INFO:root:Episode 1152,last 100 episodes, mean rewards  19.29,  steps 884736, 795.36 steps/s\n",
      "INFO:root:Episode 1168,last 100 episodes, mean rewards  19.47,  steps 897024, 801.58 steps/s\n",
      "INFO:root:Episode 1184,last 100 episodes, mean rewards  19.44,  steps 909312, 796.53 steps/s\n",
      "INFO:root:Episode 1200,last 100 episodes, mean rewards  20.12,  steps 921600, 796.19 steps/s\n",
      "INFO:root:Episode 1216,last 100 episodes, mean rewards  20.18,  steps 933888, 790.80 steps/s\n",
      "INFO:root:Episode 1232,last 100 episodes, mean rewards  20.21,  steps 946176, 798.38 steps/s\n",
      "INFO:root:Episode 1248,last 100 episodes, mean rewards  19.99,  steps 958464, 798.89 steps/s\n",
      "INFO:root:Episode 1264,last 100 episodes, mean rewards  19.82,  steps 970752, 798.44 steps/s\n",
      "INFO:root:Episode 1280,last 100 episodes, mean rewards  20.13,  steps 983040, 788.83 steps/s\n",
      "INFO:root:Episode 1296,last 100 episodes, mean rewards  19.94,  steps 995328, 799.19 steps/s\n",
      "INFO:root:Episode 1312,last 100 episodes, mean rewards  20.17,  steps 1007616, 787.92 steps/s\n",
      "INFO:root:Episode 1328,last 100 episodes, mean rewards  20.14,  steps 1019904, 802.37 steps/s\n",
      "INFO:root:Episode 1344,last 100 episodes, mean rewards  20.46,  steps 1032192, 811.73 steps/s\n",
      "INFO:root:Episode 1360,last 100 episodes, mean rewards  20.32,  steps 1044480, 811.21 steps/s\n",
      "INFO:root:Episode 1376,last 100 episodes, mean rewards  20.25,  steps 1056768, 791.75 steps/s\n",
      "INFO:root:Episode 1392,last 100 episodes, mean rewards  20.51,  steps 1069056, 808.23 steps/s\n",
      "INFO:root:Episode 1408,last 100 episodes, mean rewards  20.12,  steps 1081344, 798.89 steps/s\n",
      "INFO:root:Episode 1424,last 100 episodes, mean rewards  20.52,  steps 1093632, 792.00 steps/s\n",
      "INFO:root:Episode 1440,last 100 episodes, mean rewards  20.99,  steps 1105920, 791.27 steps/s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Episode 1456,last 100 episodes, mean rewards  20.53,  steps 1118208, 797.19 steps/s\n",
      "INFO:root:Episode 1472,last 100 episodes, mean rewards  21.32,  steps 1130496, 801.90 steps/s\n",
      "INFO:root:Episode 1488,last 100 episodes, mean rewards  21.61,  steps 1142784, 799.71 steps/s\n",
      "INFO:root:Episode 1504,last 100 episodes, mean rewards  21.41,  steps 1155072, 798.24 steps/s\n",
      "INFO:root:Episode 1520,last 100 episodes, mean rewards  21.25,  steps 1167360, 796.78 steps/s\n",
      "INFO:root:Episode 1536,last 100 episodes, mean rewards  21.02,  steps 1179648, 793.81 steps/s\n",
      "INFO:root:Episode 1552,last 100 episodes, mean rewards  21.35,  steps 1191936, 810.63 steps/s\n",
      "INFO:root:Episode 1568,last 100 episodes, mean rewards  21.56,  steps 1204224, 788.46 steps/s\n",
      "INFO:root:Episode 1584,last 100 episodes, mean rewards  21.72,  steps 1216512, 786.75 steps/s\n",
      "INFO:root:Episode 1600,last 100 episodes, mean rewards  22.10,  steps 1228800, 783.73 steps/s\n",
      "INFO:root:Episode 1616,last 100 episodes, mean rewards  21.94,  steps 1241088, 802.30 steps/s\n",
      "INFO:root:Episode 1632,last 100 episodes, mean rewards  22.96,  steps 1253376, 794.66 steps/s\n",
      "INFO:root:Episode 1648,last 100 episodes, mean rewards  22.61,  steps 1265664, 797.72 steps/s\n",
      "INFO:root:Episode 1664,last 100 episodes, mean rewards  22.84,  steps 1277952, 804.89 steps/s\n",
      "INFO:root:Episode 1680,last 100 episodes, mean rewards  23.30,  steps 1290240, 808.61 steps/s\n",
      "INFO:root:Episode 1696,last 100 episodes, mean rewards  23.30,  steps 1302528, 797.23 steps/s\n",
      "INFO:root:Episode 1712,last 100 episodes, mean rewards  23.83,  steps 1314816, 792.02 steps/s\n",
      "INFO:root:Episode 1728,last 100 episodes, mean rewards  23.39,  steps 1327104, 797.50 steps/s\n",
      "INFO:root:Episode 1744,last 100 episodes, mean rewards  22.92,  steps 1339392, 791.99 steps/s\n",
      "INFO:root:Episode 1760,last 100 episodes, mean rewards  23.34,  steps 1351680, 797.26 steps/s\n",
      "INFO:root:Episode 1776,last 100 episodes, mean rewards  22.93,  steps 1363968, 785.52 steps/s\n",
      "INFO:root:Episode 1792,last 100 episodes, mean rewards  22.52,  steps 1376256, 793.27 steps/s\n",
      "INFO:root:Episode 1808,last 100 episodes, mean rewards  22.31,  steps 1388544, 801.53 steps/s\n",
      "INFO:root:Episode 1824,last 100 episodes, mean rewards  22.12,  steps 1400832, 786.24 steps/s\n",
      "INFO:root:Episode 1840,last 100 episodes, mean rewards  22.17,  steps 1413120, 794.51 steps/s\n",
      "INFO:root:Episode 1856,last 100 episodes, mean rewards  22.45,  steps 1425408, 800.18 steps/s\n",
      "INFO:root:Episode 1872,last 100 episodes, mean rewards  22.26,  steps 1437696, 795.69 steps/s\n",
      "INFO:root:Episode 1888,last 100 episodes, mean rewards  22.52,  steps 1449984, 801.08 steps/s\n",
      "INFO:root:Episode 1904,last 100 episodes, mean rewards  23.42,  steps 1462272, 786.91 steps/s\n",
      "INFO:root:Episode 1920,last 100 episodes, mean rewards  23.38,  steps 1474560, 802.12 steps/s\n",
      "INFO:root:Episode 1936,last 100 episodes, mean rewards  23.56,  steps 1486848, 790.78 steps/s\n",
      "INFO:root:Episode 1952,last 100 episodes, mean rewards  23.20,  steps 1499136, 803.53 steps/s\n",
      "INFO:root:Episode 1968,last 100 episodes, mean rewards  22.72,  steps 1511424, 799.50 steps/s\n",
      "INFO:root:Episode 1984,last 100 episodes, mean rewards  22.79,  steps 1523712, 791.00 steps/s\n",
      "INFO:root:Episode 2000,last 100 episodes, mean rewards  22.22,  steps 1536000, 791.35 steps/s\n",
      "INFO:root:Episode 2016,last 100 episodes, mean rewards  22.11,  steps 1548288, 800.88 steps/s\n",
      "INFO:root:Episode 2032,last 100 episodes, mean rewards  22.51,  steps 1560576, 791.15 steps/s\n",
      "INFO:root:Episode 2048,last 100 episodes, mean rewards  23.54,  steps 1572864, 800.73 steps/s\n",
      "INFO:root:Episode 2064,last 100 episodes, mean rewards  24.09,  steps 1585152, 797.48 steps/s\n",
      "INFO:root:Episode 2080,last 100 episodes, mean rewards  24.02,  steps 1597440, 795.67 steps/s\n",
      "INFO:root:Episode 2096,last 100 episodes, mean rewards  24.29,  steps 1609728, 797.40 steps/s\n",
      "INFO:root:Episode 2112,last 100 episodes, mean rewards  23.72,  steps 1622016, 800.05 steps/s\n",
      "INFO:root:Episode 2128,last 100 episodes, mean rewards  23.63,  steps 1634304, 790.13 steps/s\n",
      "INFO:root:Episode 2144,last 100 episodes, mean rewards  22.77,  steps 1646592, 789.78 steps/s\n",
      "INFO:root:Episode 2160,last 100 episodes, mean rewards  22.61,  steps 1658880, 793.28 steps/s\n",
      "INFO:root:Episode 2176,last 100 episodes, mean rewards  22.46,  steps 1671168, 795.52 steps/s\n",
      "INFO:root:Episode 2192,last 100 episodes, mean rewards  22.95,  steps 1683456, 787.38 steps/s\n",
      "INFO:root:Episode 2208,last 100 episodes, mean rewards  22.87,  steps 1695744, 787.65 steps/s\n",
      "INFO:root:Episode 2224,last 100 episodes, mean rewards  22.96,  steps 1708032, 794.68 steps/s\n",
      "INFO:root:Episode 2240,last 100 episodes, mean rewards  23.07,  steps 1720320, 794.04 steps/s\n",
      "INFO:root:Episode 2256,last 100 episodes, mean rewards  22.72,  steps 1732608, 791.33 steps/s\n",
      "INFO:root:Episode 2272,last 100 episodes, mean rewards  22.59,  steps 1744896, 797.03 steps/s\n",
      "INFO:root:Episode 2288,last 100 episodes, mean rewards  22.43,  steps 1757184, 796.31 steps/s\n",
      "INFO:root:Episode 2304,last 100 episodes, mean rewards  22.62,  steps 1769472, 792.29 steps/s\n",
      "INFO:root:Episode 2320,last 100 episodes, mean rewards  22.93,  steps 1781760, 785.36 steps/s\n",
      "INFO:root:Episode 2336,last 100 episodes, mean rewards  23.32,  steps 1794048, 808.45 steps/s\n",
      "INFO:root:Episode 2352,last 100 episodes, mean rewards  23.17,  steps 1806336, 791.97 steps/s\n",
      "INFO:root:Episode 2368,last 100 episodes, mean rewards  23.56,  steps 1818624, 790.60 steps/s\n",
      "INFO:root:Episode 2384,last 100 episodes, mean rewards  22.99,  steps 1830912, 797.40 steps/s\n",
      "INFO:root:Episode 2400,last 100 episodes, mean rewards  22.25,  steps 1843200, 793.98 steps/s\n",
      "INFO:root:Episode 2416,last 100 episodes, mean rewards  21.86,  steps 1855488, 789.21 steps/s\n",
      "INFO:root:Episode 2432,last 100 episodes, mean rewards  20.73,  steps 1867776, 787.54 steps/s\n",
      "INFO:root:Episode 2448,last 100 episodes, mean rewards  20.73,  steps 1880064, 793.14 steps/s\n",
      "INFO:root:Episode 2464,last 100 episodes, mean rewards  20.34,  steps 1892352, 795.94 steps/s\n",
      "INFO:root:Episode 2480,last 100 episodes, mean rewards  20.88,  steps 1904640, 788.42 steps/s\n",
      "INFO:root:Episode 2496,last 100 episodes, mean rewards  21.69,  steps 1916928, 785.88 steps/s\n",
      "INFO:root:Episode 2512,last 100 episodes, mean rewards  21.78,  steps 1929216, 792.05 steps/s\n",
      "INFO:root:Episode 2528,last 100 episodes, mean rewards  22.31,  steps 1941504, 809.75 steps/s\n",
      "INFO:root:Episode 2544,last 100 episodes, mean rewards  22.59,  steps 1953792, 803.09 steps/s\n",
      "INFO:root:Episode 2560,last 100 episodes, mean rewards  22.89,  steps 1966080, 795.55 steps/s\n",
      "INFO:root:Episode 2576,last 100 episodes, mean rewards  22.69,  steps 1978368, 788.92 steps/s\n",
      "INFO:root:Episode 2592,last 100 episodes, mean rewards  21.99,  steps 1990656, 785.42 steps/s\n",
      "INFO:root:Episode 2608,last 100 episodes, mean rewards  22.45,  steps 2002944, 795.81 steps/s\n",
      "INFO:root:Episode 2624,last 100 episodes, mean rewards  23.01,  steps 2015232, 814.88 steps/s\n",
      "INFO:root:Episode 2640,last 100 episodes, mean rewards  22.98,  steps 2027520, 793.47 steps/s\n",
      "INFO:root:Episode 2656,last 100 episodes, mean rewards  22.80,  steps 2039808, 809.49 steps/s\n",
      "INFO:root:Episode 2672,last 100 episodes, mean rewards  22.87,  steps 2052096, 794.43 steps/s\n",
      "INFO:root:Episode 2688,last 100 episodes, mean rewards  23.79,  steps 2064384, 789.28 steps/s\n",
      "INFO:root:Episode 2704,last 100 episodes, mean rewards  23.88,  steps 2076672, 792.23 steps/s\n",
      "INFO:root:Episode 2720,last 100 episodes, mean rewards  23.97,  steps 2088960, 792.36 steps/s\n",
      "INFO:root:Episode 2736,last 100 episodes, mean rewards  24.54,  steps 2101248, 792.78 steps/s\n",
      "INFO:root:Episode 2752,last 100 episodes, mean rewards  25.47,  steps 2113536, 796.14 steps/s\n",
      "INFO:root:Episode 2768,last 100 episodes, mean rewards  26.01,  steps 2125824, 806.30 steps/s\n",
      "INFO:root:Episode 2784,last 100 episodes, mean rewards  25.79,  steps 2138112, 796.74 steps/s\n",
      "INFO:root:Episode 2800,last 100 episodes, mean rewards  25.84,  steps 2150400, 793.40 steps/s\n",
      "INFO:root:Episode 2816,last 100 episodes, mean rewards  25.24,  steps 2162688, 789.61 steps/s\n",
      "INFO:root:Episode 2832,last 100 episodes, mean rewards  24.67,  steps 2174976, 793.36 steps/s\n",
      "INFO:root:Episode 2848,last 100 episodes, mean rewards  24.72,  steps 2187264, 797.10 steps/s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Episode 2864,last 100 episodes, mean rewards  24.22,  steps 2199552, 792.04 steps/s\n",
      "INFO:root:Episode 2880,last 100 episodes, mean rewards  24.07,  steps 2211840, 794.57 steps/s\n",
      "INFO:root:Episode 2896,last 100 episodes, mean rewards  24.22,  steps 2224128, 793.32 steps/s\n",
      "INFO:root:Episode 2912,last 100 episodes, mean rewards  24.39,  steps 2236416, 787.78 steps/s\n",
      "INFO:root:Episode 2928,last 100 episodes, mean rewards  24.67,  steps 2248704, 799.41 steps/s\n",
      "INFO:root:Episode 2944,last 100 episodes, mean rewards  24.82,  steps 2260992, 787.93 steps/s\n",
      "INFO:root:Episode 2960,last 100 episodes, mean rewards  24.96,  steps 2273280, 812.42 steps/s\n",
      "INFO:root:Episode 2976,last 100 episodes, mean rewards  24.35,  steps 2285568, 789.37 steps/s\n",
      "INFO:root:Episode 2992,last 100 episodes, mean rewards  24.15,  steps 2297856, 767.00 steps/s\n",
      "INFO:root:Episode 3008,last 100 episodes, mean rewards  24.55,  steps 2310144, 780.09 steps/s\n",
      "INFO:root:Episode 3024,last 100 episodes, mean rewards  24.53,  steps 2322432, 808.02 steps/s\n",
      "INFO:root:Episode 3040,last 100 episodes, mean rewards  24.69,  steps 2334720, 793.95 steps/s\n",
      "INFO:root:Episode 3056,last 100 episodes, mean rewards  24.62,  steps 2347008, 789.46 steps/s\n",
      "INFO:root:Episode 3072,last 100 episodes, mean rewards  25.23,  steps 2359296, 786.17 steps/s\n",
      "INFO:root:Episode 3088,last 100 episodes, mean rewards  25.77,  steps 2371584, 778.09 steps/s\n",
      "INFO:root:Episode 3104,last 100 episodes, mean rewards  25.72,  steps 2383872, 796.04 steps/s\n",
      "INFO:root:Episode 3120,last 100 episodes, mean rewards  25.86,  steps 2396160, 796.66 steps/s\n",
      "INFO:root:Episode 3136,last 100 episodes, mean rewards  25.53,  steps 2408448, 806.82 steps/s\n",
      "INFO:root:Episode 3152,last 100 episodes, mean rewards  25.50,  steps 2420736, 798.46 steps/s\n",
      "INFO:root:Episode 3168,last 100 episodes, mean rewards  24.97,  steps 2433024, 799.26 steps/s\n",
      "INFO:root:Episode 3184,last 100 episodes, mean rewards  25.11,  steps 2445312, 789.43 steps/s\n",
      "INFO:root:Episode 3200,last 100 episodes, mean rewards  24.84,  steps 2457600, 797.03 steps/s\n",
      "INFO:root:Episode 3216,last 100 episodes, mean rewards  24.41,  steps 2469888, 798.83 steps/s\n",
      "INFO:root:Episode 3232,last 100 episodes, mean rewards  24.40,  steps 2482176, 791.35 steps/s\n",
      "INFO:root:Episode 3248,last 100 episodes, mean rewards  24.13,  steps 2494464, 787.94 steps/s\n",
      "INFO:root:Episode 3264,last 100 episodes, mean rewards  23.90,  steps 2506752, 797.58 steps/s\n",
      "INFO:root:Episode 3280,last 100 episodes, mean rewards  24.01,  steps 2519040, 800.05 steps/s\n",
      "INFO:root:Episode 3296,last 100 episodes, mean rewards  24.16,  steps 2531328, 790.96 steps/s\n",
      "INFO:root:Episode 3312,last 100 episodes, mean rewards  24.25,  steps 2543616, 801.90 steps/s\n",
      "INFO:root:Episode 3328,last 100 episodes, mean rewards  24.48,  steps 2555904, 802.39 steps/s\n",
      "INFO:root:Episode 3344,last 100 episodes, mean rewards  24.58,  steps 2568192, 792.27 steps/s\n",
      "INFO:root:Episode 3360,last 100 episodes, mean rewards  24.88,  steps 2580480, 782.43 steps/s\n",
      "INFO:root:Episode 3376,last 100 episodes, mean rewards  24.28,  steps 2592768, 793.85 steps/s\n",
      "INFO:root:Episode 3392,last 100 episodes, mean rewards  23.56,  steps 2605056, 793.34 steps/s\n",
      "INFO:root:Episode 3408,last 100 episodes, mean rewards  23.31,  steps 2617344, 798.15 steps/s\n",
      "INFO:root:Episode 3424,last 100 episodes, mean rewards  23.41,  steps 2629632, 804.75 steps/s\n",
      "INFO:root:Episode 3440,last 100 episodes, mean rewards  23.23,  steps 2641920, 804.88 steps/s\n",
      "INFO:root:Episode 3456,last 100 episodes, mean rewards  23.35,  steps 2654208, 794.33 steps/s\n",
      "INFO:root:Episode 3472,last 100 episodes, mean rewards  23.93,  steps 2666496, 794.24 steps/s\n",
      "INFO:root:Episode 3488,last 100 episodes, mean rewards  24.57,  steps 2678784, 800.54 steps/s\n",
      "INFO:root:Episode 3504,last 100 episodes, mean rewards  25.23,  steps 2691072, 793.44 steps/s\n",
      "INFO:root:Episode 3520,last 100 episodes, mean rewards  25.42,  steps 2703360, 790.98 steps/s\n",
      "INFO:root:Episode 3536,last 100 episodes, mean rewards  25.57,  steps 2715648, 802.35 steps/s\n",
      "INFO:root:Episode 3552,last 100 episodes, mean rewards  25.36,  steps 2727936, 784.42 steps/s\n",
      "INFO:root:Episode 3568,last 100 episodes, mean rewards  24.07,  steps 2740224, 792.71 steps/s\n",
      "INFO:root:Episode 3584,last 100 episodes, mean rewards  23.07,  steps 2752512, 788.96 steps/s\n",
      "INFO:root:Episode 3600,last 100 episodes, mean rewards  22.23,  steps 2764800, 801.82 steps/s\n",
      "INFO:root:Episode 3616,last 100 episodes, mean rewards  21.66,  steps 2777088, 796.88 steps/s\n",
      "INFO:root:Episode 3632,last 100 episodes, mean rewards  21.67,  steps 2789376, 795.23 steps/s\n",
      "INFO:root:Episode 3648,last 100 episodes, mean rewards  21.62,  steps 2801664, 807.23 steps/s\n",
      "INFO:root:Episode 3664,last 100 episodes, mean rewards  22.79,  steps 2813952, 795.73 steps/s\n",
      "INFO:root:Episode 3680,last 100 episodes, mean rewards  24.01,  steps 2826240, 790.75 steps/s\n",
      "INFO:root:Episode 3696,last 100 episodes, mean rewards  24.44,  steps 2838528, 807.43 steps/s\n",
      "INFO:root:Episode 3712,last 100 episodes, mean rewards  25.06,  steps 2850816, 800.72 steps/s\n",
      "INFO:root:Episode 3728,last 100 episodes, mean rewards  25.40,  steps 2863104, 781.74 steps/s\n",
      "INFO:root:Episode 3744,last 100 episodes, mean rewards  25.42,  steps 2875392, 790.13 steps/s\n",
      "INFO:root:Episode 3760,last 100 episodes, mean rewards  25.16,  steps 2887680, 790.03 steps/s\n",
      "INFO:root:Episode 3776,last 100 episodes, mean rewards  24.99,  steps 2899968, 800.61 steps/s\n",
      "INFO:root:Episode 3792,last 100 episodes, mean rewards  25.02,  steps 2912256, 778.54 steps/s\n",
      "INFO:root:Episode 3808,last 100 episodes, mean rewards  24.75,  steps 2924544, 800.06 steps/s\n",
      "INFO:root:Episode 3824,last 100 episodes, mean rewards  24.63,  steps 2936832, 787.54 steps/s\n",
      "INFO:root:Episode 3840,last 100 episodes, mean rewards  24.70,  steps 2949120, 795.61 steps/s\n",
      "INFO:root:Episode 3856,last 100 episodes, mean rewards  24.98,  steps 2961408, 795.70 steps/s\n",
      "INFO:root:Episode 3872,last 100 episodes, mean rewards  25.21,  steps 2973696, 797.65 steps/s\n",
      "INFO:root:Episode 3888,last 100 episodes, mean rewards  25.32,  steps 2985984, 801.55 steps/s\n",
      "INFO:root:Episode 3904,last 100 episodes, mean rewards  25.32,  steps 2998272, 783.60 steps/s\n",
      "INFO:root:Episode 3920,last 100 episodes, mean rewards  25.31,  steps 3010560, 785.22 steps/s\n",
      "INFO:root:Episode 3936,last 100 episodes, mean rewards  25.17,  steps 3022848, 792.70 steps/s\n",
      "INFO:root:Episode 3952,last 100 episodes, mean rewards  24.66,  steps 3035136, 788.06 steps/s\n",
      "INFO:root:Episode 3968,last 100 episodes, mean rewards  24.49,  steps 3047424, 785.70 steps/s\n",
      "INFO:root:Episode 3984,last 100 episodes, mean rewards  24.44,  steps 3059712, 796.19 steps/s\n",
      "INFO:root:Episode 4000,last 100 episodes, mean rewards  24.21,  steps 3072000, 792.60 steps/s\n",
      "INFO:root:Episode 4016,last 100 episodes, mean rewards  23.89,  steps 3084288, 791.15 steps/s\n",
      "INFO:root:Episode 4032,last 100 episodes, mean rewards  23.52,  steps 3096576, 796.25 steps/s\n",
      "INFO:root:Episode 4048,last 100 episodes, mean rewards  22.96,  steps 3108864, 795.25 steps/s\n",
      "INFO:root:Episode 4064,last 100 episodes, mean rewards  22.90,  steps 3121152, 795.90 steps/s\n",
      "INFO:root:Episode 4080,last 100 episodes, mean rewards  21.44,  steps 3133440, 782.56 steps/s\n",
      "INFO:root:Episode 4096,last 100 episodes, mean rewards  20.27,  steps 3145728, 783.94 steps/s\n",
      "INFO:root:Episode 4112,last 100 episodes, mean rewards  19.60,  steps 3158016, 788.42 steps/s\n",
      "INFO:root:Episode 4128,last 100 episodes, mean rewards  19.05,  steps 3170304, 786.71 steps/s\n",
      "INFO:root:Episode 4144,last 100 episodes, mean rewards  18.52,  steps 3182592, 782.81 steps/s\n",
      "INFO:root:Episode 4160,last 100 episodes, mean rewards  18.74,  steps 3194880, 793.98 steps/s\n",
      "INFO:root:Episode 4176,last 100 episodes, mean rewards  19.26,  steps 3207168, 787.61 steps/s\n",
      "INFO:root:Episode 4192,last 100 episodes, mean rewards  20.09,  steps 3219456, 799.58 steps/s\n",
      "INFO:root:Episode 4208,last 100 episodes, mean rewards  21.52,  steps 3231744, 798.42 steps/s\n",
      "INFO:root:Episode 4224,last 100 episodes, mean rewards  22.52,  steps 3244032, 777.15 steps/s\n",
      "INFO:root:Episode 4240,last 100 episodes, mean rewards  23.79,  steps 3256320, 799.82 steps/s\n",
      "INFO:root:Episode 4256,last 100 episodes, mean rewards  24.68,  steps 3268608, 807.71 steps/s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Episode 4272,last 100 episodes, mean rewards  25.08,  steps 3280896, 797.66 steps/s\n",
      "INFO:root:Episode 4288,last 100 episodes, mean rewards  25.88,  steps 3293184, 795.15 steps/s\n",
      "INFO:root:Episode 4304,last 100 episodes, mean rewards  25.76,  steps 3305472, 803.91 steps/s\n",
      "INFO:root:Episode 4320,last 100 episodes, mean rewards  25.22,  steps 3317760, 793.81 steps/s\n",
      "INFO:root:Episode 4336,last 100 episodes, mean rewards  24.87,  steps 3330048, 788.47 steps/s\n",
      "INFO:root:Episode 4352,last 100 episodes, mean rewards  24.92,  steps 3342336, 798.39 steps/s\n",
      "INFO:root:Episode 4368,last 100 episodes, mean rewards  24.53,  steps 3354624, 789.96 steps/s\n",
      "INFO:root:Episode 4384,last 100 episodes, mean rewards  24.88,  steps 3366912, 787.51 steps/s\n",
      "INFO:root:Episode 4400,last 100 episodes, mean rewards  25.11,  steps 3379200, 795.67 steps/s\n",
      "INFO:root:Episode 4416,last 100 episodes, mean rewards  25.38,  steps 3391488, 798.37 steps/s\n",
      "INFO:root:Episode 4432,last 100 episodes, mean rewards  25.42,  steps 3403776, 791.00 steps/s\n",
      "INFO:root:Episode 4448,last 100 episodes, mean rewards  25.45,  steps 3416064, 794.73 steps/s\n",
      "INFO:root:Episode 4464,last 100 episodes, mean rewards  25.66,  steps 3428352, 794.91 steps/s\n",
      "INFO:root:Episode 4480,last 100 episodes, mean rewards  25.90,  steps 3440640, 798.29 steps/s\n",
      "INFO:root:Episode 4496,last 100 episodes, mean rewards  26.23,  steps 3452928, 797.37 steps/s\n",
      "INFO:root:Episode 4512,last 100 episodes, mean rewards  26.58,  steps 3465216, 802.09 steps/s\n",
      "INFO:root:Episode 4528,last 100 episodes, mean rewards  27.04,  steps 3477504, 797.90 steps/s\n",
      "INFO:root:Episode 4544,last 100 episodes, mean rewards  27.12,  steps 3489792, 792.67 steps/s\n",
      "INFO:root:Episode 4560,last 100 episodes, mean rewards  27.09,  steps 3502080, 790.18 steps/s\n",
      "INFO:root:Episode 4576,last 100 episodes, mean rewards  26.54,  steps 3514368, 792.38 steps/s\n",
      "INFO:root:Episode 4592,last 100 episodes, mean rewards  26.27,  steps 3526656, 790.70 steps/s\n",
      "INFO:root:Episode 4608,last 100 episodes, mean rewards  26.02,  steps 3538944, 792.33 steps/s\n",
      "INFO:root:Episode 4624,last 100 episodes, mean rewards  25.79,  steps 3551232, 795.37 steps/s\n",
      "INFO:root:Episode 4640,last 100 episodes, mean rewards  25.67,  steps 3563520, 785.60 steps/s\n",
      "INFO:root:Episode 4656,last 100 episodes, mean rewards  25.75,  steps 3575808, 787.50 steps/s\n",
      "INFO:root:Episode 4672,last 100 episodes, mean rewards  25.75,  steps 3588096, 790.47 steps/s\n",
      "INFO:root:Episode 4688,last 100 episodes, mean rewards  26.17,  steps 3600384, 784.76 steps/s\n",
      "INFO:root:Episode 4704,last 100 episodes, mean rewards  26.24,  steps 3612672, 784.88 steps/s\n",
      "INFO:root:Episode 4720,last 100 episodes, mean rewards  26.74,  steps 3624960, 809.21 steps/s\n",
      "INFO:root:Episode 4736,last 100 episodes, mean rewards  26.82,  steps 3637248, 806.31 steps/s\n",
      "INFO:root:Episode 4752,last 100 episodes, mean rewards  26.64,  steps 3649536, 768.83 steps/s\n",
      "INFO:root:Episode 4768,last 100 episodes, mean rewards  26.73,  steps 3661824, 794.67 steps/s\n",
      "INFO:root:Episode 4784,last 100 episodes, mean rewards  26.66,  steps 3674112, 804.98 steps/s\n",
      "INFO:root:Episode 4800,last 100 episodes, mean rewards  26.36,  steps 3686400, 793.70 steps/s\n",
      "INFO:root:Episode 4816,last 100 episodes, mean rewards  26.21,  steps 3698688, 792.65 steps/s\n",
      "INFO:root:Episode 4832,last 100 episodes, mean rewards  25.73,  steps 3710976, 800.01 steps/s\n",
      "INFO:root:Episode 4848,last 100 episodes, mean rewards  25.42,  steps 3723264, 791.89 steps/s\n",
      "INFO:root:Episode 4864,last 100 episodes, mean rewards  25.11,  steps 3735552, 797.32 steps/s\n",
      "INFO:root:Episode 4880,last 100 episodes, mean rewards  24.81,  steps 3747840, 792.08 steps/s\n",
      "INFO:root:Episode 4896,last 100 episodes, mean rewards  24.68,  steps 3760128, 796.33 steps/s\n",
      "INFO:root:Episode 4912,last 100 episodes, mean rewards  24.46,  steps 3772416, 794.59 steps/s\n",
      "INFO:root:Episode 4928,last 100 episodes, mean rewards  24.60,  steps 3784704, 801.26 steps/s\n",
      "INFO:root:Episode 4944,last 100 episodes, mean rewards  24.91,  steps 3796992, 797.07 steps/s\n",
      "INFO:root:Episode 4960,last 100 episodes, mean rewards  25.19,  steps 3809280, 799.88 steps/s\n",
      "INFO:root:Episode 4976,last 100 episodes, mean rewards  25.78,  steps 3821568, 798.54 steps/s\n",
      "INFO:root:Episode 4992,last 100 episodes, mean rewards  25.94,  steps 3833856, 792.95 steps/s\n",
      "INFO:root:Episode 5008,last 100 episodes, mean rewards  26.22,  steps 3846144, 788.34 steps/s\n",
      "INFO:root:Episode 5024,last 100 episodes, mean rewards  25.96,  steps 3858432, 807.39 steps/s\n",
      "INFO:root:Episode 5040,last 100 episodes, mean rewards  25.78,  steps 3870720, 799.46 steps/s\n",
      "INFO:root:Episode 5056,last 100 episodes, mean rewards  25.96,  steps 3883008, 793.45 steps/s\n",
      "INFO:root:Episode 5072,last 100 episodes, mean rewards  24.96,  steps 3895296, 797.86 steps/s\n",
      "INFO:root:Episode 5088,last 100 episodes, mean rewards  24.37,  steps 3907584, 793.74 steps/s\n",
      "INFO:root:Episode 5104,last 100 episodes, mean rewards  24.01,  steps 3919872, 795.36 steps/s\n",
      "INFO:root:Episode 5120,last 100 episodes, mean rewards  23.68,  steps 3932160, 805.07 steps/s\n",
      "INFO:root:Episode 5136,last 100 episodes, mean rewards  23.49,  steps 3944448, 781.58 steps/s\n",
      "INFO:root:Episode 5152,last 100 episodes, mean rewards  23.66,  steps 3956736, 794.00 steps/s\n",
      "INFO:root:Episode 5168,last 100 episodes, mean rewards  24.10,  steps 3969024, 812.09 steps/s\n",
      "INFO:root:Episode 5184,last 100 episodes, mean rewards  24.59,  steps 3981312, 795.23 steps/s\n",
      "INFO:root:Episode 5200,last 100 episodes, mean rewards  24.91,  steps 3993600, 791.76 steps/s\n",
      "INFO:root:Episode 5216,last 100 episodes, mean rewards  24.85,  steps 4005888, 785.18 steps/s\n",
      "INFO:root:Episode 5232,last 100 episodes, mean rewards  25.73,  steps 4018176, 789.31 steps/s\n",
      "INFO:root:Episode 5248,last 100 episodes, mean rewards  25.44,  steps 4030464, 792.58 steps/s\n",
      "INFO:root:Episode 5264,last 100 episodes, mean rewards  25.03,  steps 4042752, 795.97 steps/s\n",
      "INFO:root:Episode 5280,last 100 episodes, mean rewards  25.22,  steps 4055040, 790.00 steps/s\n",
      "INFO:root:Episode 5296,last 100 episodes, mean rewards  24.89,  steps 4067328, 794.88 steps/s\n",
      "INFO:root:Episode 5312,last 100 episodes, mean rewards  24.77,  steps 4079616, 793.33 steps/s\n",
      "INFO:root:Episode 5328,last 100 episodes, mean rewards  24.33,  steps 4091904, 787.47 steps/s\n",
      "INFO:root:Episode 5344,last 100 episodes, mean rewards  24.54,  steps 4104192, 800.30 steps/s\n",
      "INFO:root:Episode 5360,last 100 episodes, mean rewards  24.81,  steps 4116480, 798.78 steps/s\n",
      "INFO:root:Episode 5376,last 100 episodes, mean rewards  24.46,  steps 4128768, 791.19 steps/s\n",
      "INFO:root:Episode 5392,last 100 episodes, mean rewards  24.17,  steps 4141056, 783.42 steps/s\n",
      "INFO:root:Episode 5408,last 100 episodes, mean rewards  24.65,  steps 4153344, 799.46 steps/s\n",
      "INFO:root:Episode 5424,last 100 episodes, mean rewards  24.64,  steps 4165632, 781.99 steps/s\n",
      "INFO:root:Episode 5440,last 100 episodes, mean rewards  24.67,  steps 4177920, 794.82 steps/s\n",
      "INFO:root:Episode 5456,last 100 episodes, mean rewards  24.80,  steps 4190208, 795.30 steps/s\n",
      "INFO:root:Episode 5472,last 100 episodes, mean rewards  24.86,  steps 4202496, 790.42 steps/s\n",
      "INFO:root:Episode 5488,last 100 episodes, mean rewards  25.62,  steps 4214784, 780.07 steps/s\n",
      "INFO:root:Episode 5504,last 100 episodes, mean rewards  25.79,  steps 4227072, 789.52 steps/s\n",
      "INFO:root:Episode 5520,last 100 episodes, mean rewards  26.19,  steps 4239360, 802.35 steps/s\n",
      "INFO:root:Episode 5536,last 100 episodes, mean rewards  26.27,  steps 4251648, 784.63 steps/s\n",
      "INFO:root:Episode 5552,last 100 episodes, mean rewards  26.71,  steps 4263936, 793.74 steps/s\n",
      "INFO:root:Episode 5568,last 100 episodes, mean rewards  26.69,  steps 4276224, 795.74 steps/s\n",
      "INFO:root:Episode 5584,last 100 episodes, mean rewards  26.43,  steps 4288512, 785.10 steps/s\n",
      "INFO:root:Episode 5600,last 100 episodes, mean rewards  26.15,  steps 4300800, 801.99 steps/s\n",
      "INFO:root:Episode 5616,last 100 episodes, mean rewards  25.69,  steps 4313088, 792.43 steps/s\n",
      "INFO:root:Episode 5632,last 100 episodes, mean rewards  25.41,  steps 4325376, 795.07 steps/s\n",
      "INFO:root:Episode 5648,last 100 episodes, mean rewards  25.01,  steps 4337664, 790.47 steps/s\n",
      "INFO:root:Episode 5664,last 100 episodes, mean rewards  24.59,  steps 4349952, 788.15 steps/s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Episode 5680,last 100 episodes, mean rewards  24.38,  steps 4362240, 785.81 steps/s\n",
      "INFO:root:Episode 5696,last 100 episodes, mean rewards  24.01,  steps 4374528, 797.55 steps/s\n",
      "INFO:root:Episode 5712,last 100 episodes, mean rewards  23.59,  steps 4386816, 789.85 steps/s\n",
      "INFO:root:Episode 5728,last 100 episodes, mean rewards  23.43,  steps 4399104, 783.42 steps/s\n",
      "INFO:root:Episode 5744,last 100 episodes, mean rewards  23.29,  steps 4411392, 788.74 steps/s\n",
      "INFO:root:Episode 5760,last 100 episodes, mean rewards  23.22,  steps 4423680, 789.23 steps/s\n",
      "INFO:root:Episode 5776,last 100 episodes, mean rewards  22.47,  steps 4435968, 801.31 steps/s\n",
      "INFO:root:Episode 5792,last 100 episodes, mean rewards  21.83,  steps 4448256, 797.28 steps/s\n",
      "INFO:root:Episode 5808,last 100 episodes, mean rewards  21.93,  steps 4460544, 800.03 steps/s\n",
      "INFO:root:Episode 5824,last 100 episodes, mean rewards  21.16,  steps 4472832, 794.34 steps/s\n",
      "INFO:root:Episode 5840,last 100 episodes, mean rewards  19.64,  steps 4485120, 787.78 steps/s\n",
      "INFO:root:Episode 5856,last 100 episodes, mean rewards  18.25,  steps 4497408, 789.44 steps/s\n",
      "INFO:root:Episode 5872,last 100 episodes, mean rewards  17.43,  steps 4509696, 786.50 steps/s\n",
      "INFO:root:Episode 5888,last 100 episodes, mean rewards  17.57,  steps 4521984, 800.95 steps/s\n",
      "INFO:root:Episode 5904,last 100 episodes, mean rewards  17.55,  steps 4534272, 796.36 steps/s\n",
      "INFO:root:Episode 5920,last 100 episodes, mean rewards  17.81,  steps 4546560, 789.94 steps/s\n",
      "INFO:root:Episode 5936,last 100 episodes, mean rewards  18.92,  steps 4558848, 789.65 steps/s\n",
      "INFO:root:Episode 5952,last 100 episodes, mean rewards  19.80,  steps 4571136, 806.37 steps/s\n",
      "INFO:root:Episode 5968,last 100 episodes, mean rewards  20.57,  steps 4583424, 792.51 steps/s\n",
      "INFO:root:Episode 5984,last 100 episodes, mean rewards  21.50,  steps 4595712, 790.94 steps/s\n",
      "INFO:root:Episode 6000,last 100 episodes, mean rewards  21.69,  steps 4608000, 796.01 steps/s\n",
      "INFO:root:Episode 6016,last 100 episodes, mean rewards  22.04,  steps 4620288, 797.55 steps/s\n",
      "INFO:root:Episode 6032,last 100 episodes, mean rewards  22.25,  steps 4632576, 796.68 steps/s\n",
      "INFO:root:Episode 6048,last 100 episodes, mean rewards  22.78,  steps 4644864, 786.30 steps/s\n",
      "INFO:root:Episode 6064,last 100 episodes, mean rewards  22.98,  steps 4657152, 793.91 steps/s\n",
      "INFO:root:Episode 6080,last 100 episodes, mean rewards  22.52,  steps 4669440, 790.33 steps/s\n",
      "INFO:root:Episode 6096,last 100 episodes, mean rewards  22.34,  steps 4681728, 789.70 steps/s\n",
      "INFO:root:Episode 6112,last 100 episodes, mean rewards  22.00,  steps 4694016, 782.26 steps/s\n",
      "INFO:root:Episode 6128,last 100 episodes, mean rewards  21.61,  steps 4706304, 790.03 steps/s\n",
      "INFO:root:Episode 6144,last 100 episodes, mean rewards  21.15,  steps 4718592, 782.47 steps/s\n",
      "INFO:root:Episode 6160,last 100 episodes, mean rewards  21.41,  steps 4730880, 797.60 steps/s\n",
      "INFO:root:Episode 6176,last 100 episodes, mean rewards  21.01,  steps 4743168, 790.63 steps/s\n",
      "INFO:root:Episode 6192,last 100 episodes, mean rewards  20.72,  steps 4755456, 794.96 steps/s\n",
      "INFO:root:Episode 6208,last 100 episodes, mean rewards  20.81,  steps 4767744, 793.44 steps/s\n",
      "INFO:root:Episode 6224,last 100 episodes, mean rewards  21.11,  steps 4780032, 790.43 steps/s\n",
      "INFO:root:Episode 6240,last 100 episodes, mean rewards  21.00,  steps 4792320, 790.35 steps/s\n",
      "INFO:root:Episode 6256,last 100 episodes, mean rewards  20.21,  steps 4804608, 799.24 steps/s\n",
      "INFO:root:Episode 6272,last 100 episodes, mean rewards  20.62,  steps 4816896, 792.62 steps/s\n",
      "INFO:root:Episode 6288,last 100 episodes, mean rewards  20.69,  steps 4829184, 784.63 steps/s\n",
      "INFO:root:Episode 6304,last 100 episodes, mean rewards  20.78,  steps 4841472, 790.40 steps/s\n",
      "INFO:root:Episode 6320,last 100 episodes, mean rewards  20.78,  steps 4853760, 803.61 steps/s\n",
      "INFO:root:Episode 6336,last 100 episodes, mean rewards  20.51,  steps 4866048, 783.15 steps/s\n",
      "INFO:root:Episode 6352,last 100 episodes, mean rewards  21.24,  steps 4878336, 783.70 steps/s\n",
      "INFO:root:Episode 6368,last 100 episodes, mean rewards  22.06,  steps 4890624, 795.85 steps/s\n",
      "INFO:root:Episode 6384,last 100 episodes, mean rewards  22.10,  steps 4902912, 797.99 steps/s\n",
      "INFO:root:Episode 6400,last 100 episodes, mean rewards  21.71,  steps 4915200, 786.72 steps/s\n",
      "INFO:root:Episode 6416,last 100 episodes, mean rewards  21.02,  steps 4927488, 781.60 steps/s\n",
      "INFO:root:Episode 6432,last 100 episodes, mean rewards  20.70,  steps 4939776, 785.07 steps/s\n",
      "INFO:root:Episode 6448,last 100 episodes, mean rewards  19.60,  steps 4952064, 781.63 steps/s\n",
      "INFO:root:Episode 6464,last 100 episodes, mean rewards  18.20,  steps 4964352, 788.23 steps/s\n",
      "INFO:root:Episode 6480,last 100 episodes, mean rewards  18.08,  steps 4976640, 792.71 steps/s\n",
      "INFO:root:Episode 6496,last 100 episodes, mean rewards  18.33,  steps 4988928, 795.30 steps/s\n",
      "INFO:root:Episode 6512,last 100 episodes, mean rewards  18.51,  steps 5001216, 791.51 steps/s\n",
      "INFO:root:Episode 6528,last 100 episodes, mean rewards  19.31,  steps 5013504, 795.04 steps/s\n",
      "INFO:root:Episode 6544,last 100 episodes, mean rewards  20.02,  steps 5025792, 788.46 steps/s\n",
      "INFO:root:Episode 6560,last 100 episodes, mean rewards  20.95,  steps 5038080, 789.10 steps/s\n",
      "INFO:root:Episode 6576,last 100 episodes, mean rewards  19.38,  steps 5050368, 778.38 steps/s\n",
      "INFO:root:Episode 6592,last 100 episodes, mean rewards  18.66,  steps 5062656, 781.10 steps/s\n",
      "INFO:root:Episode 6608,last 100 episodes, mean rewards  18.14,  steps 5074944, 786.96 steps/s\n",
      "INFO:root:Episode 6624,last 100 episodes, mean rewards  16.71,  steps 5087232, 775.44 steps/s\n",
      "INFO:root:Episode 6640,last 100 episodes, mean rewards  14.76,  steps 5099520, 780.78 steps/s\n",
      "INFO:root:Episode 6656,last 100 episodes, mean rewards  14.48,  steps 5111808, 786.24 steps/s\n",
      "INFO:root:Episode 6672,last 100 episodes, mean rewards  16.45,  steps 5124096, 784.21 steps/s\n",
      "INFO:root:Episode 6688,last 100 episodes, mean rewards  18.21,  steps 5136384, 788.29 steps/s\n",
      "INFO:root:Episode 6704,last 100 episodes, mean rewards  18.97,  steps 5148672, 781.68 steps/s\n",
      "INFO:root:Episode 6720,last 100 episodes, mean rewards  20.48,  steps 5160960, 787.27 steps/s\n",
      "INFO:root:Episode 6736,last 100 episodes, mean rewards  22.97,  steps 5173248, 795.14 steps/s\n",
      "INFO:root:Episode 6752,last 100 episodes, mean rewards  23.96,  steps 5185536, 808.08 steps/s\n",
      "INFO:root:Episode 6768,last 100 episodes, mean rewards  24.56,  steps 5197824, 795.66 steps/s\n",
      "INFO:root:Episode 6784,last 100 episodes, mean rewards  25.20,  steps 5210112, 788.48 steps/s\n",
      "INFO:root:Episode 6800,last 100 episodes, mean rewards  25.79,  steps 5222400, 788.35 steps/s\n",
      "INFO:root:Episode 6816,last 100 episodes, mean rewards  26.49,  steps 5234688, 797.62 steps/s\n",
      "INFO:root:Episode 6832,last 100 episodes, mean rewards  26.38,  steps 5246976, 793.76 steps/s\n",
      "INFO:root:Episode 6848,last 100 episodes, mean rewards  26.13,  steps 5259264, 792.94 steps/s\n",
      "INFO:root:Episode 6864,last 100 episodes, mean rewards  25.43,  steps 5271552, 793.14 steps/s\n",
      "INFO:root:Episode 6880,last 100 episodes, mean rewards  24.15,  steps 5283840, 807.55 steps/s\n",
      "INFO:root:Episode 6896,last 100 episodes, mean rewards  23.31,  steps 5296128, 791.70 steps/s\n",
      "INFO:root:Episode 6912,last 100 episodes, mean rewards  21.85,  steps 5308416, 795.85 steps/s\n",
      "INFO:root:Episode 6928,last 100 episodes, mean rewards  20.10,  steps 5320704, 791.21 steps/s\n",
      "INFO:root:Episode 6944,last 100 episodes, mean rewards  17.25,  steps 5332992, 790.73 steps/s\n",
      "INFO:root:Episode 6960,last 100 episodes, mean rewards  14.41,  steps 5345280, 789.28 steps/s\n",
      "INFO:root:Episode 6976,last 100 episodes, mean rewards  12.37,  steps 5357568, 778.98 steps/s\n",
      "INFO:root:Episode 6992,last 100 episodes, mean rewards  10.34,  steps 5369856, 789.88 steps/s\n",
      "INFO:root:Episode 7008,last 100 episodes, mean rewards  8.47,  steps 5382144, 782.72 steps/s\n",
      "INFO:root:Episode 7024,last 100 episodes, mean rewards  7.25,  steps 5394432, 787.01 steps/s\n",
      "INFO:root:Episode 7040,last 100 episodes, mean rewards  7.34,  steps 5406720, 794.20 steps/s\n",
      "INFO:root:Episode 7056,last 100 episodes, mean rewards  7.82,  steps 5419008, 795.58 steps/s\n",
      "INFO:root:Episode 7072,last 100 episodes, mean rewards  8.79,  steps 5431296, 786.84 steps/s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Episode 7088,last 100 episodes, mean rewards  9.69,  steps 5443584, 786.25 steps/s\n",
      "INFO:root:Episode 7104,last 100 episodes, mean rewards  10.59,  steps 5455872, 794.32 steps/s\n",
      "INFO:root:Episode 7120,last 100 episodes, mean rewards  11.40,  steps 5468160, 790.66 steps/s\n",
      "INFO:root:Episode 7136,last 100 episodes, mean rewards  11.32,  steps 5480448, 788.43 steps/s\n",
      "INFO:root:Episode 7152,last 100 episodes, mean rewards  11.80,  steps 5492736, 792.81 steps/s\n",
      "INFO:root:Episode 7168,last 100 episodes, mean rewards  11.73,  steps 5505024, 787.83 steps/s\n",
      "INFO:root:Episode 7184,last 100 episodes, mean rewards  11.30,  steps 5517312, 785.84 steps/s\n",
      "INFO:root:Episode 7200,last 100 episodes, mean rewards  10.72,  steps 5529600, 788.43 steps/s\n",
      "INFO:root:Episode 7216,last 100 episodes, mean rewards  9.96,  steps 5541888, 786.34 steps/s\n",
      "INFO:root:Episode 7232,last 100 episodes, mean rewards  9.53,  steps 5554176, 781.27 steps/s\n",
      "INFO:root:Episode 7248,last 100 episodes, mean rewards  8.85,  steps 5566464, 781.72 steps/s\n",
      "INFO:root:Episode 7264,last 100 episodes, mean rewards  8.28,  steps 5578752, 783.79 steps/s\n",
      "INFO:root:Episode 7280,last 100 episodes, mean rewards  7.84,  steps 5591040, 795.54 steps/s\n",
      "INFO:root:Episode 7296,last 100 episodes, mean rewards  7.38,  steps 5603328, 793.61 steps/s\n",
      "INFO:root:Episode 7312,last 100 episodes, mean rewards  7.10,  steps 5615616, 775.66 steps/s\n",
      "INFO:root:Episode 7328,last 100 episodes, mean rewards  7.31,  steps 5627904, 787.96 steps/s\n",
      "INFO:root:Episode 7344,last 100 episodes, mean rewards  7.40,  steps 5640192, 775.86 steps/s\n",
      "INFO:root:Episode 7360,last 100 episodes, mean rewards  7.44,  steps 5652480, 781.34 steps/s\n",
      "INFO:root:Episode 7376,last 100 episodes, mean rewards  7.47,  steps 5664768, 781.34 steps/s\n",
      "INFO:root:Episode 7392,last 100 episodes, mean rewards  7.34,  steps 5677056, 784.44 steps/s\n",
      "INFO:root:Episode 7408,last 100 episodes, mean rewards  7.09,  steps 5689344, 785.45 steps/s\n",
      "INFO:root:Episode 7424,last 100 episodes, mean rewards  6.92,  steps 5701632, 784.66 steps/s\n",
      "INFO:root:Episode 7440,last 100 episodes, mean rewards  6.81,  steps 5713920, 770.65 steps/s\n",
      "INFO:root:Episode 7456,last 100 episodes, mean rewards  6.51,  steps 5726208, 778.83 steps/s\n",
      "INFO:root:Episode 7472,last 100 episodes, mean rewards  6.25,  steps 5738496, 776.24 steps/s\n",
      "INFO:root:Episode 7488,last 100 episodes, mean rewards  6.01,  steps 5750784, 774.17 steps/s\n",
      "INFO:root:Episode 7504,last 100 episodes, mean rewards  5.62,  steps 5763072, 776.49 steps/s\n",
      "INFO:root:Episode 7520,last 100 episodes, mean rewards  5.42,  steps 5775360, 776.41 steps/s\n",
      "INFO:root:Episode 7536,last 100 episodes, mean rewards  4.96,  steps 5787648, 767.88 steps/s\n",
      "INFO:root:Episode 7552,last 100 episodes, mean rewards  4.48,  steps 5799936, 775.15 steps/s\n",
      "INFO:root:Episode 7568,last 100 episodes, mean rewards  4.02,  steps 5812224, 785.12 steps/s\n",
      "INFO:root:Episode 7584,last 100 episodes, mean rewards  3.68,  steps 5824512, 786.81 steps/s\n",
      "INFO:root:Episode 7600,last 100 episodes, mean rewards  4.12,  steps 5836800, 778.53 steps/s\n",
      "INFO:root:Episode 7616,last 100 episodes, mean rewards  5.38,  steps 5849088, 787.61 steps/s\n",
      "INFO:root:Episode 7632,last 100 episodes, mean rewards  7.60,  steps 5861376, 794.39 steps/s\n",
      "INFO:root:Episode 7648,last 100 episodes, mean rewards  10.10,  steps 5873664, 792.65 steps/s\n",
      "INFO:root:Episode 7664,last 100 episodes, mean rewards  12.55,  steps 5885952, 792.27 steps/s\n",
      "INFO:root:Episode 7680,last 100 episodes, mean rewards  14.97,  steps 5898240, 792.25 steps/s\n",
      "INFO:root:Episode 7696,last 100 episodes, mean rewards  17.36,  steps 5910528, 790.33 steps/s\n",
      "INFO:root:Episode 7712,last 100 episodes, mean rewards  18.50,  steps 5922816, 811.18 steps/s\n",
      "INFO:root:Episode 7728,last 100 episodes, mean rewards  18.69,  steps 5935104, 799.16 steps/s\n",
      "INFO:root:Episode 7744,last 100 episodes, mean rewards  18.63,  steps 5947392, 794.90 steps/s\n",
      "INFO:root:Episode 7760,last 100 episodes, mean rewards  18.59,  steps 5959680, 790.38 steps/s\n",
      "INFO:root:Episode 7776,last 100 episodes, mean rewards  18.75,  steps 5971968, 802.93 steps/s\n",
      "INFO:root:Episode 7792,last 100 episodes, mean rewards  18.63,  steps 5984256, 793.58 steps/s\n",
      "INFO:root:Episode 7808,last 100 episodes, mean rewards  18.56,  steps 5996544, 799.58 steps/s\n",
      "INFO:root:Episode 7824,last 100 episodes, mean rewards  18.50,  steps 6008832, 787.39 steps/s\n",
      "INFO:root:Episode 7840,last 100 episodes, mean rewards  18.51,  steps 6021120, 795.34 steps/s\n",
      "INFO:root:Episode 7856,last 100 episodes, mean rewards  17.97,  steps 6033408, 789.92 steps/s\n",
      "INFO:root:Episode 7872,last 100 episodes, mean rewards  17.26,  steps 6045696, 789.23 steps/s\n",
      "INFO:root:Episode 7888,last 100 episodes, mean rewards  17.17,  steps 6057984, 806.75 steps/s\n",
      "INFO:root:Episode 7904,last 100 episodes, mean rewards  17.10,  steps 6070272, 801.10 steps/s\n",
      "INFO:root:Episode 7920,last 100 episodes, mean rewards  17.44,  steps 6082560, 816.19 steps/s\n",
      "INFO:root:Episode 7936,last 100 episodes, mean rewards  17.78,  steps 6094848, 804.24 steps/s\n",
      "INFO:root:Episode 7952,last 100 episodes, mean rewards  18.01,  steps 6107136, 803.85 steps/s\n",
      "INFO:root:Episode 7968,last 100 episodes, mean rewards  18.31,  steps 6119424, 789.54 steps/s\n",
      "INFO:root:Episode 7984,last 100 episodes, mean rewards  18.41,  steps 6131712, 794.10 steps/s\n",
      "INFO:root:Episode 8000,last 100 episodes, mean rewards  18.30,  steps 6144000, 801.22 steps/s\n",
      "INFO:root:Episode 8016,last 100 episodes, mean rewards  17.82,  steps 6156288, 791.17 steps/s\n",
      "INFO:root:Episode 8032,last 100 episodes, mean rewards  17.45,  steps 6168576, 809.05 steps/s\n",
      "INFO:root:Episode 8048,last 100 episodes, mean rewards  16.74,  steps 6180864, 795.07 steps/s\n",
      "INFO:root:Episode 8064,last 100 episodes, mean rewards  17.25,  steps 6193152, 800.91 steps/s\n",
      "INFO:root:Episode 8080,last 100 episodes, mean rewards  17.70,  steps 6205440, 793.62 steps/s\n",
      "INFO:root:Episode 8096,last 100 episodes, mean rewards  18.14,  steps 6217728, 805.10 steps/s\n",
      "INFO:root:Episode 8112,last 100 episodes, mean rewards  18.15,  steps 6230016, 790.43 steps/s\n",
      "INFO:root:Episode 8128,last 100 episodes, mean rewards  18.43,  steps 6242304, 793.33 steps/s\n",
      "INFO:root:Episode 8144,last 100 episodes, mean rewards  19.57,  steps 6254592, 793.88 steps/s\n",
      "INFO:root:Episode 8160,last 100 episodes, mean rewards  19.61,  steps 6266880, 795.10 steps/s\n",
      "INFO:root:Episode 8176,last 100 episodes, mean rewards  19.77,  steps 6279168, 799.84 steps/s\n",
      "INFO:root:Episode 8192,last 100 episodes, mean rewards  19.64,  steps 6291456, 802.26 steps/s\n",
      "INFO:root:Episode 8208,last 100 episodes, mean rewards  20.10,  steps 6303744, 805.91 steps/s\n",
      "INFO:root:Episode 8224,last 100 episodes, mean rewards  19.65,  steps 6316032, 793.52 steps/s\n",
      "INFO:root:Episode 8240,last 100 episodes, mean rewards  18.03,  steps 6328320, 790.10 steps/s\n",
      "INFO:root:Episode 8256,last 100 episodes, mean rewards  16.79,  steps 6340608, 787.46 steps/s\n",
      "INFO:root:Episode 8272,last 100 episodes, mean rewards  16.19,  steps 6352896, 795.02 steps/s\n",
      "INFO:root:Episode 8288,last 100 episodes, mean rewards  16.06,  steps 6365184, 790.00 steps/s\n",
      "INFO:root:Episode 8304,last 100 episodes, mean rewards  15.62,  steps 6377472, 796.37 steps/s\n",
      "INFO:root:Episode 8320,last 100 episodes, mean rewards  15.82,  steps 6389760, 798.89 steps/s\n",
      "INFO:root:Episode 8336,last 100 episodes, mean rewards  16.76,  steps 6402048, 789.36 steps/s\n",
      "INFO:root:Episode 8352,last 100 episodes, mean rewards  18.32,  steps 6414336, 815.79 steps/s\n",
      "INFO:root:Episode 8368,last 100 episodes, mean rewards  18.91,  steps 6426624, 798.50 steps/s\n",
      "INFO:root:Episode 8384,last 100 episodes, mean rewards  18.68,  steps 6438912, 795.11 steps/s\n",
      "INFO:root:Episode 8400,last 100 episodes, mean rewards  18.79,  steps 6451200, 792.17 steps/s\n",
      "INFO:root:Episode 8416,last 100 episodes, mean rewards  18.22,  steps 6463488, 797.66 steps/s\n",
      "INFO:root:Episode 8432,last 100 episodes, mean rewards  17.41,  steps 6475776, 795.33 steps/s\n",
      "INFO:root:Episode 8448,last 100 episodes, mean rewards  16.65,  steps 6488064, 793.35 steps/s\n",
      "INFO:root:Episode 8464,last 100 episodes, mean rewards  16.22,  steps 6500352, 807.64 steps/s\n",
      "INFO:root:Episode 8480,last 100 episodes, mean rewards  16.06,  steps 6512640, 789.75 steps/s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Episode 8496,last 100 episodes, mean rewards  15.24,  steps 6524928, 790.30 steps/s\n",
      "INFO:root:Episode 8512,last 100 episodes, mean rewards  15.39,  steps 6537216, 791.00 steps/s\n",
      "INFO:root:Episode 8528,last 100 episodes, mean rewards  15.63,  steps 6549504, 786.31 steps/s\n",
      "INFO:root:Episode 8544,last 100 episodes, mean rewards  16.53,  steps 6561792, 789.41 steps/s\n",
      "INFO:root:Episode 8560,last 100 episodes, mean rewards  17.15,  steps 6574080, 790.57 steps/s\n",
      "INFO:root:Episode 8576,last 100 episodes, mean rewards  17.62,  steps 6586368, 807.62 steps/s\n",
      "INFO:root:Episode 8592,last 100 episodes, mean rewards  18.40,  steps 6598656, 788.14 steps/s\n",
      "INFO:root:Episode 8608,last 100 episodes, mean rewards  19.10,  steps 6610944, 802.12 steps/s\n",
      "INFO:root:Episode 8624,last 100 episodes, mean rewards  20.02,  steps 6623232, 792.97 steps/s\n",
      "INFO:root:Episode 8640,last 100 episodes, mean rewards  19.75,  steps 6635520, 799.28 steps/s\n",
      "INFO:root:Episode 8656,last 100 episodes, mean rewards  19.55,  steps 6647808, 793.39 steps/s\n",
      "INFO:root:Episode 8672,last 100 episodes, mean rewards  19.70,  steps 6660096, 800.17 steps/s\n",
      "INFO:root:Episode 8688,last 100 episodes, mean rewards  20.07,  steps 6672384, 802.55 steps/s\n",
      "INFO:root:Episode 8704,last 100 episodes, mean rewards  20.09,  steps 6684672, 796.11 steps/s\n",
      "INFO:root:Episode 8720,last 100 episodes, mean rewards  19.99,  steps 6696960, 792.81 steps/s\n",
      "INFO:root:Episode 8736,last 100 episodes, mean rewards  19.64,  steps 6709248, 793.54 steps/s\n",
      "INFO:root:Episode 8752,last 100 episodes, mean rewards  19.76,  steps 6721536, 786.99 steps/s\n",
      "INFO:root:Episode 8768,last 100 episodes, mean rewards  18.92,  steps 6733824, 790.44 steps/s\n",
      "INFO:root:Episode 8784,last 100 episodes, mean rewards  18.44,  steps 6746112, 796.36 steps/s\n",
      "INFO:root:Episode 8800,last 100 episodes, mean rewards  17.52,  steps 6758400, 786.66 steps/s\n",
      "INFO:root:Episode 8816,last 100 episodes, mean rewards  17.07,  steps 6770688, 794.18 steps/s\n",
      "INFO:root:Episode 8832,last 100 episodes, mean rewards  17.00,  steps 6782976, 796.90 steps/s\n",
      "INFO:root:Episode 8848,last 100 episodes, mean rewards  16.81,  steps 6795264, 789.65 steps/s\n",
      "INFO:root:Episode 8864,last 100 episodes, mean rewards  17.32,  steps 6807552, 784.41 steps/s\n",
      "INFO:root:Episode 8880,last 100 episodes, mean rewards  17.42,  steps 6819840, 797.38 steps/s\n",
      "INFO:root:Episode 8896,last 100 episodes, mean rewards  17.71,  steps 6832128, 794.85 steps/s\n",
      "INFO:root:Episode 8912,last 100 episodes, mean rewards  17.82,  steps 6844416, 790.59 steps/s\n",
      "INFO:root:Episode 8928,last 100 episodes, mean rewards  17.40,  steps 6856704, 787.93 steps/s\n",
      "INFO:root:Episode 8944,last 100 episodes, mean rewards  16.83,  steps 6868992, 791.19 steps/s\n",
      "INFO:root:Episode 8960,last 100 episodes, mean rewards  16.38,  steps 6881280, 783.76 steps/s\n",
      "INFO:root:Episode 8976,last 100 episodes, mean rewards  15.63,  steps 6893568, 782.55 steps/s\n",
      "INFO:root:Episode 8992,last 100 episodes, mean rewards  15.14,  steps 6905856, 788.05 steps/s\n",
      "INFO:root:Episode 9008,last 100 episodes, mean rewards  15.04,  steps 6918144, 782.18 steps/s\n",
      "INFO:root:Episode 9024,last 100 episodes, mean rewards  15.49,  steps 6930432, 785.30 steps/s\n",
      "INFO:root:Episode 9040,last 100 episodes, mean rewards  16.30,  steps 6942720, 801.87 steps/s\n",
      "INFO:root:Episode 9056,last 100 episodes, mean rewards  17.23,  steps 6955008, 794.64 steps/s\n",
      "INFO:root:Episode 9072,last 100 episodes, mean rewards  17.73,  steps 6967296, 777.98 steps/s\n",
      "INFO:root:Episode 9088,last 100 episodes, mean rewards  17.39,  steps 6979584, 790.72 steps/s\n",
      "INFO:root:Episode 9104,last 100 episodes, mean rewards  17.28,  steps 6991872, 787.05 steps/s\n",
      "INFO:root:Episode 9120,last 100 episodes, mean rewards  17.05,  steps 7004160, 800.18 steps/s\n",
      "INFO:root:Episode 9136,last 100 episodes, mean rewards  17.21,  steps 7016448, 791.07 steps/s\n",
      "INFO:root:Episode 9152,last 100 episodes, mean rewards  17.14,  steps 7028736, 791.32 steps/s\n",
      "INFO:root:Episode 9168,last 100 episodes, mean rewards  17.87,  steps 7041024, 808.38 steps/s\n",
      "INFO:root:Episode 9184,last 100 episodes, mean rewards  18.93,  steps 7053312, 794.06 steps/s\n",
      "INFO:root:Episode 9200,last 100 episodes, mean rewards  19.51,  steps 7065600, 806.86 steps/s\n",
      "INFO:root:Episode 9216,last 100 episodes, mean rewards  19.86,  steps 7077888, 801.76 steps/s\n",
      "INFO:root:Episode 9232,last 100 episodes, mean rewards  20.08,  steps 7090176, 785.67 steps/s\n",
      "INFO:root:Episode 9248,last 100 episodes, mean rewards  19.48,  steps 7102464, 792.37 steps/s\n",
      "INFO:root:Episode 9264,last 100 episodes, mean rewards  19.71,  steps 7114752, 786.11 steps/s\n",
      "INFO:root:Episode 9280,last 100 episodes, mean rewards  19.25,  steps 7127040, 788.81 steps/s\n",
      "INFO:root:Episode 9296,last 100 episodes, mean rewards  19.55,  steps 7139328, 794.89 steps/s\n",
      "INFO:root:Episode 9312,last 100 episodes, mean rewards  19.43,  steps 7151616, 782.39 steps/s\n",
      "INFO:root:Episode 9328,last 100 episodes, mean rewards  18.59,  steps 7163904, 781.75 steps/s\n",
      "INFO:root:Episode 9344,last 100 episodes, mean rewards  17.63,  steps 7176192, 786.46 steps/s\n",
      "INFO:root:Episode 9360,last 100 episodes, mean rewards  16.14,  steps 7188480, 780.76 steps/s\n",
      "INFO:root:Episode 9376,last 100 episodes, mean rewards  15.10,  steps 7200768, 779.33 steps/s\n",
      "INFO:root:Episode 9392,last 100 episodes, mean rewards  14.43,  steps 7213056, 782.07 steps/s\n",
      "INFO:root:Episode 9408,last 100 episodes, mean rewards  13.37,  steps 7225344, 786.40 steps/s\n",
      "INFO:root:Episode 9424,last 100 episodes, mean rewards  13.12,  steps 7237632, 793.63 steps/s\n",
      "INFO:root:Episode 9440,last 100 episodes, mean rewards  13.04,  steps 7249920, 782.45 steps/s\n",
      "INFO:root:Episode 9456,last 100 episodes, mean rewards  13.48,  steps 7262208, 794.86 steps/s\n",
      "INFO:root:Episode 9472,last 100 episodes, mean rewards  13.96,  steps 7274496, 788.25 steps/s\n",
      "INFO:root:Episode 9488,last 100 episodes, mean rewards  13.73,  steps 7286784, 776.71 steps/s\n",
      "INFO:root:Episode 9504,last 100 episodes, mean rewards  13.90,  steps 7299072, 787.18 steps/s\n",
      "INFO:root:Episode 9520,last 100 episodes, mean rewards  13.87,  steps 7311360, 792.31 steps/s\n",
      "INFO:root:Episode 9536,last 100 episodes, mean rewards  13.69,  steps 7323648, 785.09 steps/s\n",
      "INFO:root:Episode 9552,last 100 episodes, mean rewards  13.23,  steps 7335936, 784.37 steps/s\n",
      "INFO:root:Episode 9568,last 100 episodes, mean rewards  12.49,  steps 7348224, 788.39 steps/s\n",
      "INFO:root:Episode 9584,last 100 episodes, mean rewards  11.63,  steps 7360512, 778.59 steps/s\n",
      "INFO:root:Episode 9600,last 100 episodes, mean rewards  10.84,  steps 7372800, 782.99 steps/s\n",
      "INFO:root:Episode 9616,last 100 episodes, mean rewards  10.25,  steps 7385088, 781.64 steps/s\n",
      "INFO:root:Episode 9632,last 100 episodes, mean rewards  9.68,  steps 7397376, 777.05 steps/s\n",
      "INFO:root:Episode 9648,last 100 episodes, mean rewards  9.06,  steps 7409664, 774.70 steps/s\n",
      "INFO:root:Episode 9664,last 100 episodes, mean rewards  9.05,  steps 7421952, 791.07 steps/s\n",
      "INFO:root:Episode 9680,last 100 episodes, mean rewards  9.22,  steps 7434240, 791.41 steps/s\n",
      "INFO:root:Episode 9696,last 100 episodes, mean rewards  9.18,  steps 7446528, 782.47 steps/s\n",
      "INFO:root:Episode 9712,last 100 episodes, mean rewards  8.97,  steps 7458816, 777.10 steps/s\n",
      "INFO:root:Episode 9728,last 100 episodes, mean rewards  8.79,  steps 7471104, 779.43 steps/s\n",
      "INFO:root:Episode 9744,last 100 episodes, mean rewards  8.86,  steps 7483392, 782.30 steps/s\n",
      "INFO:root:Episode 9760,last 100 episodes, mean rewards  8.56,  steps 7495680, 790.85 steps/s\n",
      "INFO:root:Episode 9776,last 100 episodes, mean rewards  8.27,  steps 7507968, 779.19 steps/s\n",
      "INFO:root:Episode 9792,last 100 episodes, mean rewards  8.11,  steps 7520256, 776.82 steps/s\n",
      "INFO:root:Episode 9808,last 100 episodes, mean rewards  8.11,  steps 7532544, 767.15 steps/s\n",
      "INFO:root:Episode 9824,last 100 episodes, mean rewards  8.12,  steps 7544832, 769.55 steps/s\n",
      "INFO:root:Episode 9840,last 100 episodes, mean rewards  8.15,  steps 7557120, 769.12 steps/s\n",
      "INFO:root:Episode 9856,last 100 episodes, mean rewards  8.24,  steps 7569408, 767.26 steps/s\n",
      "INFO:root:Episode 9872,last 100 episodes, mean rewards  8.40,  steps 7581696, 769.53 steps/s\n",
      "INFO:root:Episode 9888,last 100 episodes, mean rewards  8.53,  steps 7593984, 771.18 steps/s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Episode 9904,last 100 episodes, mean rewards  8.65,  steps 7606272, 765.50 steps/s\n",
      "INFO:root:Episode 9920,last 100 episodes, mean rewards  8.67,  steps 7618560, 765.02 steps/s\n",
      "INFO:root:Episode 9936,last 100 episodes, mean rewards  8.08,  steps 7630848, 761.90 steps/s\n",
      "INFO:root:Episode 9952,last 100 episodes, mean rewards  7.73,  steps 7643136, 775.93 steps/s\n",
      "INFO:root:Episode 9968,last 100 episodes, mean rewards  7.25,  steps 7655424, 763.31 steps/s\n",
      "INFO:root:Episode 9984,last 100 episodes, mean rewards  6.90,  steps 7667712, 772.90 steps/s\n",
      "INFO:root:Episode 10000,last 100 episodes, mean rewards  6.94,  steps 7680000, 769.31 steps/s\n",
      "INFO:root:Episode 10016,last 100 episodes, mean rewards  6.77,  steps 7692288, 768.05 steps/s\n",
      "INFO:root:Episode 10032,last 100 episodes, mean rewards  7.22,  steps 7704576, 770.55 steps/s\n",
      "INFO:root:Episode 10048,last 100 episodes, mean rewards  7.36,  steps 7716864, 778.62 steps/s\n",
      "INFO:root:Episode 10064,last 100 episodes, mean rewards  7.98,  steps 7729152, 778.89 steps/s\n",
      "INFO:root:Episode 10080,last 100 episodes, mean rewards  8.24,  steps 7741440, 771.21 steps/s\n",
      "INFO:root:Episode 10096,last 100 episodes, mean rewards  8.19,  steps 7753728, 772.98 steps/s\n",
      "INFO:root:Episode 10112,last 100 episodes, mean rewards  8.49,  steps 7766016, 778.85 steps/s\n",
      "INFO:root:Episode 10128,last 100 episodes, mean rewards  8.61,  steps 7778304, 779.42 steps/s\n",
      "INFO:root:Episode 10144,last 100 episodes, mean rewards  9.04,  steps 7790592, 793.04 steps/s\n",
      "INFO:root:Episode 10160,last 100 episodes, mean rewards  9.12,  steps 7802880, 784.64 steps/s\n",
      "INFO:root:Episode 10176,last 100 episodes, mean rewards  9.50,  steps 7815168, 784.28 steps/s\n",
      "INFO:root:Episode 10192,last 100 episodes, mean rewards  9.95,  steps 7827456, 775.36 steps/s\n",
      "INFO:root:Episode 10208,last 100 episodes, mean rewards  10.32,  steps 7839744, 777.05 steps/s\n",
      "INFO:root:Episode 10224,last 100 episodes, mean rewards  10.76,  steps 7852032, 783.40 steps/s\n",
      "INFO:root:Episode 10240,last 100 episodes, mean rewards  11.04,  steps 7864320, 785.21 steps/s\n",
      "INFO:root:Episode 10256,last 100 episodes, mean rewards  11.41,  steps 7876608, 786.28 steps/s\n",
      "INFO:root:Episode 10272,last 100 episodes, mean rewards  11.80,  steps 7888896, 780.45 steps/s\n",
      "INFO:root:Episode 10288,last 100 episodes, mean rewards  12.21,  steps 7901184, 778.42 steps/s\n",
      "INFO:root:Episode 10304,last 100 episodes, mean rewards  12.42,  steps 7913472, 777.54 steps/s\n",
      "INFO:root:Episode 10320,last 100 episodes, mean rewards  12.53,  steps 7925760, 780.79 steps/s\n",
      "INFO:root:Episode 10336,last 100 episodes, mean rewards  12.61,  steps 7938048, 800.61 steps/s\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-75f74dbd8a18>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     92\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mrun_steps_custom\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0magent\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 94\u001b[0;31m \u001b[0msuccess\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrewards_deque\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrewards_all\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mppo_continuous\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-8-75f74dbd8a18>\u001b[0m in \u001b[0;36mppo_continuous\u001b[0;34m()\u001b[0m\n\u001b[1;32m     90\u001b[0m     \u001b[0magent\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mPPOAgent\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     91\u001b[0m \u001b[0;31m#     agent.load('data/model-PPOAgent.bin')\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 92\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mrun_steps_custom\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0magent\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     93\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     94\u001b[0m \u001b[0msuccess\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrewards_deque\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrewards_all\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mppo_continuous\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-8-75f74dbd8a18>\u001b[0m in \u001b[0;36mrun_steps_custom\u001b[0;34m(agent)\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 26\u001b[0;31m         \u001b[0magent\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     27\u001b[0m         \u001b[0magent\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mswitch_task\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-7-8b75ae3fed1a>\u001b[0m in \u001b[0;36mstep\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    133\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0m_\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrollout_length\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    134\u001b[0m             \u001b[0mprediction\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnetwork\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstates\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 135\u001b[0;31m             \u001b[0mnext_states\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrewards\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mterminals\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minfo\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtask\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mto_np\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprediction\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'a'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    136\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecord_online_return\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    137\u001b[0m             \u001b[0mrewards\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreward_normalizer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrewards\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-8-75f74dbd8a18>\u001b[0m in \u001b[0;36mstep\u001b[0;34m(self, action)\u001b[0m\n\u001b[1;32m     43\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     44\u001b[0m         \u001b[0maction\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maction\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 45\u001b[0;31m         \u001b[0menv_info\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mbrain_name\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     46\u001b[0m         \u001b[0mnext_state\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0menv_info\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvector_observations\u001b[0m   \u001b[0;31m# next state\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     47\u001b[0m         \u001b[0mreward\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0menv_info\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrewards\u001b[0m                   \u001b[0;31m# reward\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/media/spiros/diskoyext/anaconda3/envs/drlnd/lib/python3.6/site-packages/unityagents/environment.py\u001b[0m in \u001b[0;36mstep\u001b[0;34m(self, vector_action, memory, text_action)\u001b[0m\n\u001b[1;32m    372\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    373\u001b[0m             \u001b[0mrl_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrl_output\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 374\u001b[0;31m             \u001b[0ms\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_state\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrl_output\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    375\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_global_done\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0ms\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    376\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0m_b\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_external_brain_names\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/media/spiros/diskoyext/anaconda3/envs/drlnd/lib/python3.6/site-packages/unityagents/environment.py\u001b[0m in \u001b[0;36m_get_state\u001b[0;34m(self, output)\u001b[0m\n\u001b[1;32m    461\u001b[0m             _data[b] = BrainInfo(\n\u001b[1;32m    462\u001b[0m                 \u001b[0mvisual_observation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvis_obs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 463\u001b[0;31m                 \u001b[0mvector_observation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstacked_vector_observation\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0magent_info_list\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    464\u001b[0m                 \u001b[0mtext_observations\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtext_observation\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0magent_info_list\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    465\u001b[0m                 \u001b[0mmemory\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmemory\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "def run_steps_custom(agent):\n",
    "    config = agent.config\n",
    "    agent_name = agent.__class__.__name__\n",
    "    t0 = time.time()\n",
    "    rewards_deque = deque(maxlen=100)\n",
    "    rewards_all = []\n",
    "    while True:\n",
    "        rewards = agent.episodic_return\n",
    "        if rewards is not None:\n",
    "            rewards_deque.append(np.mean(rewards))\n",
    "            rewards_all.append(np.mean(rewards))\n",
    "        if config.log_interval and not agent.total_steps % config.log_interval and (rewards is not None):\n",
    "            agent.logger.info('Episode %d,last %d episodes, mean rewards  %.2f,  steps %d, %.2f steps/s' % (len(rewards_all),len(rewards_deque),np.mean(rewards_deque),agent.total_steps, config.log_interval / (time.time() - t0)))\n",
    "            t0 = time.time()\n",
    "#         if config.max_steps and agent.total_steps >= config.max_steps:\n",
    "#             agent.close()\n",
    "#             return True,rewards_deque,rewards_all\n",
    "        if (rewards is not None) and np.mean(rewards_deque) > 2000:\n",
    "            agent.save('./data/model-%s.bin' % (agent_name))\n",
    "            agent.close()\n",
    "            return True,rewards_deque,rewards_all\n",
    "        if (len(rewards_all) % 200):\n",
    "            agent.save('./data/model-%s.bin' % (agent_name))\n",
    "\n",
    "\n",
    "        agent.step()\n",
    "        agent.switch_task()\n",
    "\n",
    "class CrawlerTask():\n",
    "    def __init__(self):\n",
    "#         BaseTask.__init__(self)\n",
    "        self.name = 'Reacher'\n",
    "        self.env = env\n",
    "        self.action_dim = brain.vector_action_space_size\n",
    "        self.state_dim = brain.vector_observation_space_size\n",
    "        self.info = {\"all_rewards\":None}\n",
    "        self.total_rewards = np.zeros(12)\n",
    "        self.rewards = []\n",
    "    def reset(self):\n",
    "        env_info = self.env.reset(train_mode=True)[brain_name]\n",
    "        return np.array(env_info.vector_observations)\n",
    "\n",
    "    def step(self, action):\n",
    "        action = np.clip(action, -1, 1)\n",
    "        env_info = self.env.step(action)[brain_name]\n",
    "        next_state = env_info.vector_observations   # next state\n",
    "        reward = env_info.rewards                   # reward\n",
    "        done = env_info.local_done\n",
    "\n",
    "        self.total_rewards += reward\n",
    "\n",
    "        if np.any(done):\n",
    "            if any(np.isnan(self.total_rewards.reshape(-1))):\n",
    "                self.total_rewards[np.isnan(self.total_rewards)] = -5            \n",
    "            self.info['episodic_return'] = self.total_rewards\n",
    "            self.rewards.append(self.total_rewards)\n",
    "            self.info['all_rewards'] = self.rewards\n",
    "            self.total_rewards = np.zeros(12)\n",
    "            next_state = self.reset()            \n",
    "        else:\n",
    "            self.info['episodic_return'] = None\n",
    "\n",
    "        return np.array(next_state), np.array(reward), np.array(done), self.info\n",
    "\n",
    "    def seed(self, random_seed):\n",
    "        return 10\n",
    "\n",
    "def ppo_continuous():\n",
    "    config = Config()\n",
    "    config.num_workers = num_agents\n",
    "    task_fn = lambda : CrawlerTask()\n",
    "    config.task_fn = task_fn\n",
    "    config.eval_env = task_fn()\n",
    "\n",
    "    config.network_fn = lambda: GaussianActorCriticNet(\n",
    "        config.state_dim, config.action_dim, actor_body=FCBody(config.state_dim,hidden_units=(128, 128),gate=F.leaky_relu),\n",
    "        critic_body=FCBody(config.state_dim,hidden_units=(128, 128),gate=F.leaky_relu))\n",
    "    config.optimizer_fn = lambda params: torch.optim.Adam(params, 3e-4, eps=1e-5)\n",
    "    config.discount = 0.99\n",
    "    config.use_gae = True\n",
    "    config.gae_tau = 0.99\n",
    "    config.gradient_clip = 5\n",
    "    config.rollout_length = 64\n",
    "    config.optimization_epochs = 4\n",
    "    config.mini_batch_size = 64\n",
    "    config.ppo_ratio_clip = 0.2\n",
    "    config.log_interval = 4096\n",
    "    config.max_steps = 1e4\n",
    "    config.state_normalizer = MeanStdNormalizer()\n",
    "    agent = PPOAgent(config)\n",
    "#     agent.load('data/model-PPOAgent.bin')\n",
    "    return run_steps_custom(agent)\n",
    "\n",
    "success, rewards_deque, rewards_all = ppo_continuous()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
